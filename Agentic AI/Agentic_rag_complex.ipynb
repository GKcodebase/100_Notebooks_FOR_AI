{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cb7c35c6",
      "metadata": {
        "id": "cb7c35c6"
      },
      "source": [
        "# Agentic RAG with the ReAct Pattern\n",
        "\n",
        "Overview\n",
        "This notebook demonstrates how to build an agentic Retrieval-Augmented Generation (RAG) pipeline that follows the ReAct pattern (Reasoning + Acting). The agent coordinates multiple tools to collect evidence and compose answers to complex, multi-part questions. The notebook is structured as a hands-on tutorial: setup → data ingestion → vector store & reranking → custom tools → ReAct agent construction → execution and cost reporting.\n",
        "\n",
        "Learning goals\n",
        "- Understand how to prepare and chunk source documents for embeddings.\n",
        "- Build a FAISS-backed vector store and add a reranker to improve retrieval quality.\n",
        "- Implement custom tools (web search, company director extraction, vector reranker).\n",
        "- Compose a ReAct agent that reasons about which tools to call.\n",
        "- Track API token usage and estimated cost for agent runs.\n",
        "\n",
        "Prerequisites\n",
        "- Basic Python 3.8+ and pip\n",
        "- OpenAI API access (for embeddings and LLMs)\n",
        "- SerpAPI account (for optional web search)\n",
        "- Optional: LangSmith account for LangChain tracing\n",
        "\n",
        "Notebook structure\n",
        "1. Installation & environment setup\n",
        "2. Document ingestion and chunking\n",
        "3. Vector store creation and reranking\n",
        "4. Tool definitions and agent assembly\n",
        "5. Running the agent on a complex query\n",
        "6. Token usage and cost reporting\n",
        "## Summary & Key Findings\n",
        "\n",
        "Token usage and cost (example)\n",
        "- Total Tokens Used: (value reported from run)\n",
        "- Estimated Cost: (reported estimate)\n",
        "\n",
        "Key takeaways\n",
        "- Instrumenting LangChain runs with `get_openai_callback` helps quantify LLM costs.\n",
        "- Combining vector retrieval with reranking improves answer relevance while controlling LLM context size.\n",
        "- Use caching for repeated external lookups to reduce API calls and cost.\n",
        "\n",
        "Next steps\n",
        "- Add a per-tool token logger to measure how much each tool contributes to token usage.\n",
        "- Experiment with smaller embedding or LLM models for non-critical steps to save costs.\n",
        "- Add unit tests for tool outputs and a small sample dataset for fast, reproducible demos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df4f679c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df4f679c",
        "outputId": "908b41f9-4ffc-4873-b7ad-fd4ec58f1b46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.0.7)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.12/dist-packages (1.0.5)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: langchain_classic in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: langchain_text_splitters in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: flashrank in /usr/local/lib/python3.12/dist-packages (0.2.10)\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.12/dist-packages (2.4.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (0.4.42)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (4.15.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from flashrank) (0.22.1)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.12/dist-packages (from flashrank) (1.23.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain_core) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain_core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime->flashrank) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime->flashrank) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime->flashrank) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime->flashrank) (1.13.3)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers->flashrank) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->flashrank) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->flashrank) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->flashrank) (1.2.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime->flashrank) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime->flashrank) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_core langchain_community langchain_openai langchain_classic langchain_text_splitters faiss-cpu openai flashrank google-search-results python-dotenv -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a19a2ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a19a2ca",
        "outputId": "656bf7a1-2732-444e-ae45-355235b251c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "langchain version: 1.0.5\n",
            "langchain_core version: 1.0.5\n",
            "langchain_community version: 0.4.1\n",
            "openai version: 2.8.1\n"
          ]
        }
      ],
      "source": [
        "import langchain\n",
        "import langchain_core\n",
        "import langchain_community\n",
        "import openai\n",
        "\n",
        "print(f\"langchain version: {langchain.__version__}\")\n",
        "print(f\"langchain_core version: {langchain_core.__version__}\")\n",
        "print(f\"langchain_community version: {langchain_community.__version__}\")\n",
        "print(f\"openai version: {openai.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be0615c0",
      "metadata": {
        "id": "be0615c0"
      },
      "source": [
        "## API Keys & Secrets\n",
        "\n",
        "This notebook requires API keys for the following services:\n",
        "- OpenAI: used for embeddings and LLMs.\n",
        "- SerpAPI: optional, used for web search results.\n",
        "- LangChain / LangSmith: optional, used for tracing and visualization.\n",
        "\n",
        "Options for providing keys\n",
        "- Colab/Notebook secret manager (recommended for shared notebooks).\n",
        "- A local `.env` file (for local runs). Example `.env` content:\n",
        "    OPENAI_API_KEY=sk-...\n",
        "    SERPAPI_API_KEY=...\n",
        "    LANGCHAIN_API_KEY=...\n",
        "\n",
        "Security best practices\n",
        "- Never hard-code keys in the notebook.\n",
        "- Use environment variables or secret stores.\n",
        "- Rotate keys regularly and restrict access whenever possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "048af1d3",
      "metadata": {
        "id": "048af1d3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Check if we're in a Colab environment\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import userdata\n",
        "    # Set environment variables from Colab secrets\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPEN_AI_KEY')\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = userdata.get('SERP_KEY')\n",
        "    os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANG_KEY')\n",
        "else:\n",
        "    # For local execution, load from .env file\n",
        "    from dotenv import load_dotenv\n",
        "    # Try to load .env from current directory first, then fall back to specified path\n",
        "    load_dotenv()  # Loads from current directory\n",
        "\n",
        "    # Set environment variables with validation\n",
        "    openai_key = os.getenv('OPENAI_KEY')\n",
        "    serpapi_key = os.getenv('SERPAPI_KEY')\n",
        "    langchain_key = os.getenv('LANGCHAIN_KEY')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64760806",
      "metadata": {
        "id": "64760806"
      },
      "source": [
        "## LangChain Tracing Configuration\n",
        "\n",
        "LangChain can emit execution traces to LangSmith (or other tracing backends). Tracing helps you inspect the agent's decisions, which tools were invoked, and how the final answer was composed.\n",
        "\n",
        "Why enable tracing?\n",
        "- Debug complex agent workflows.\n",
        "- Visualize tool calls and intermediate reasoning steps.\n",
        "- Collect telemetry for prompt engineering and cost optimization.\n",
        "\n",
        "How to use:\n",
        "- Set `LANGCHAIN_TRACING_V2=true` and configure `LANGCHAIN_ENDPOINT` and `LANGCHAIN_PROJECT`.\n",
        "- Log into LangSmith (or the configured tracing UI) to view runs once the agent executes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3762153f",
      "metadata": {
        "id": "3762153f"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"agentic_rag_complex\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "496f13da",
      "metadata": {
        "id": "496f13da"
      },
      "source": [
        "## Imports and Dependencies — What and Why\n",
        "\n",
        "This cell imports libraries used across the notebook:\n",
        "- LangChain family: core agent and prompt handling.\n",
        "- LangChain community modules: loaders, vectorstore integrations, rerankers.\n",
        "- Embeddings & LLM clients (OpenAI).\n",
        "- Utilities for text splitting and reranking.\n",
        "\n",
        "Notes\n",
        "- If a package is unavailable or updated, check its package name/version and adapt imports.\n",
        "- Installing via pip may require `--upgrade` to match API expectations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebc6a313",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebc6a313",
        "outputId": "0a2f0a53-ef55-4421-c984-3dea59065658"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "# Standard library imports\n",
        "import re\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from pprint import pprint\n",
        "\n",
        "# LangChain core imports\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.tools import BaseTool\n",
        "\n",
        "# LangChain community imports\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# LangChain OpenAI imports\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "# Flashrank for reranking\n",
        "from flashrank import Ranker, RerankRequest\n",
        "import langchain_community.document_compressors.flashrank_rerank as fr_mod\n",
        "fr_mod.RerankRequest = RerankRequest\n",
        "from langchain_community.document_compressors import FlashrankRerank\n",
        "\n",
        "# For retriever with compression\n",
        "from langchain_classic.retrievers import ContextualCompressionRetriever\n",
        "\n",
        "# Agent imports\n",
        "from langchain_classic.agents import create_react_agent, AgentExecutor\n",
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "from langchain_core.output_parsers import CommaSeparatedListOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4b39ba6",
      "metadata": {
        "id": "e4b39ba6"
      },
      "source": [
        "# Configuration Dictionary — Purpose & How to Customize\n",
        "\n",
        "The `defaultConfig` dictionary centralizes all runtime parameters.\n",
        "Key configuration groups:\n",
        "- Document processing: `chunkSize`, `chunkOverlap`\n",
        "- Embedding model: `embeddingModelName`\n",
        "- Retrieval: `numRetrievedDocuments`, `numSelectedDocuments`\n",
        "- Reranking: `rerankerModel`, `numRerankedDocuments`\n",
        "- LLM behavior: model names and temperatures for ReAct and name extraction\n",
        "- Tools: toggles and descriptions for director, web, and retriever tools\n",
        "\n",
        "How to tune\n",
        "- Reduce `chunkSize` to limit per-document prompt context when memory is constrained.\n",
        "- Increase `numRetrievedDocuments` for broader recall, then rely on reranker to refine quality.\n",
        "- Lower LLM temperature for deterministic outputs when extracting structured data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbbc2606",
      "metadata": {
        "id": "dbbc2606"
      },
      "outputs": [],
      "source": [
        "defaultConfig = {\n",
        "    # Document processing settings\n",
        "    \"chunkSize\": 500,\n",
        "    \"chunkOverlap\": 50,\n",
        "    \"userAgentHeader\": \"YourCompany-ResearchBot/1.0 (your@email.com)\",\n",
        "\n",
        "    # Embedding model (OpenAI)\n",
        "    \"embeddingModelName\": \"text-embedding-3-small\",\n",
        "\n",
        "    # Vector store settings\n",
        "    \"numRetrievedDocuments\": 12,\n",
        "\n",
        "    # Document formatter settings\n",
        "    \"numSelectedDocuments\": 12,\n",
        "\n",
        "    # Reranker settings (Flashrank)\n",
        "    \"rerankerModel\": \"ms-marco-TinyBERT-L-2-v2\",\n",
        "    \"numRerankedDocuments\": 5,\n",
        "\n",
        "    # Model settings for answer generation\n",
        "    \"ragAnswerModel\": \"gpt-4o\",\n",
        "    \"ragAnswerModelTemperature\": 0.7,\n",
        "\n",
        "    # URLs to process - Multiple 10-K filings\n",
        "    \"companyFilingUrls\": [\n",
        "        (\"Tesla\", \"https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm\"),\n",
        "        (\"General Motors\", \"https://www.sec.gov/Archives/edgar/data/1467858/000146785824000031/gm-20231231.htm\")\n",
        "    ],\n",
        "\n",
        "    # RAG prompt template\n",
        "    \"ragPromptTemplate\": \"\"\"\n",
        "    Give an answer for the Question using only the given Context. Use information relevant to the query from the entire context.\n",
        "    Provide a detailed answer with thorough explanations, avoiding summaries.\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Context: {context}\n",
        "\n",
        "    Answer:\n",
        "    \"\"\",\n",
        "\n",
        "    # ReAct Agent settings\n",
        "    \"reactModelName\": \"gpt-4o\",\n",
        "    \"reactModelTemperature\": 0,\n",
        "\n",
        "    \"reactPromptTemplate\": \"\"\"Your task is to gather relevant information to build context for the question. Focus on collecting details related to the question.\n",
        "    Gather as much context as possible before formulating your answer.\n",
        "\n",
        "    You have access to the following tools:\n",
        "\n",
        "    {tools}\n",
        "\n",
        "    Use the following format:\n",
        "\n",
        "    Question: the input question you must answer\n",
        "\n",
        "    Thought: you should always think about what to do\n",
        "\n",
        "    Action: the action to take, should be one of [{tool_names}]\n",
        "\n",
        "    Action Input: the input to the action\n",
        "\n",
        "    Observation: the result of the action\n",
        "\n",
        "    ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "\n",
        "    Thought: I now know the final answer\n",
        "\n",
        "    Final Answer: the final answer to the question.\n",
        "\n",
        "    Follow these steps:\n",
        "\n",
        "    Begin!\n",
        "\n",
        "    Question: {input}\n",
        "\n",
        "    Thought:{agent_scratchpad}\n",
        "    \"\"\",\n",
        "\n",
        "    \"reactVerbosity\": True,\n",
        "\n",
        "    # Name Extraction settings\n",
        "    \"nameExtractionModel\": \"gpt-4o-mini\",\n",
        "    \"nameExtractionModelTemperature\": 0.4,\n",
        "    \"nameExtractionPrompt\": \"\"\"\n",
        "    Extract and list the names of all individuals with the title 'Director' from the following text, excluding any additional information such as dates or signatures.\n",
        "    Present the names as a simple, comma-separated list.\n",
        "\n",
        "    {text}\n",
        "    \"\"\",\n",
        "\n",
        "    # Tool settings\n",
        "    \"useDirectorTool\": True,\n",
        "    \"directorToolName\": \"Company Directors Information\",\n",
        "    \"directorToolDescription\": \"Retrieve the names of company directors for a chosen company. Optionally, their LinkedIn handles can also be included. Use the format: company_name, true/false.\",\n",
        "\n",
        "    \"useWebTool\": True,\n",
        "    \"webToolName\": \"WebSearch\",\n",
        "    \"webToolDescription\": \"Performs a web search on the query.\",\n",
        "    \"numWebToolResults\": 3,\n",
        "\n",
        "    \"useRetrieverTool\": True,\n",
        "    \"retrieverToolName\": \"Vector Reranker Search\",\n",
        "    \"retrieverToolDescription\": \"Retrieves information from an embedding based vector DB containing financial data and company information. Structure query as a sentence.\",\n",
        "    \"numRetrieverToolResults\": 3\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e94cb24",
      "metadata": {
        "id": "8e94cb24"
      },
      "outputs": [],
      "source": [
        "config = defaultConfig.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e24ebb54",
      "metadata": {
        "id": "e24ebb54"
      },
      "source": [
        "# Document Processing Functions — Rationale & Behavior\n",
        "\n",
        "This section defines functions to:\n",
        "- Fetch company filings (SEC 10-Ks) using a web loader.\n",
        "- Preserve a short snippet expected to contain board/director information.\n",
        "- Split large documents into overlapping chunks suitable for embeddings.\n",
        "\n",
        "Why chunking matters\n",
        "- LLMs and embedding models operate on limited context, so documents are split into chunks.\n",
        "- Overlap ensures important sentences spanning boundaries are retained.\n",
        "- Metadata (e.g., company name) is attached to each chunk for later attribution in search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10f1b739",
      "metadata": {
        "id": "10f1b739"
      },
      "outputs": [],
      "source": [
        "def load_and_process_filings(urls: List[Tuple[str, str]], config: Dict[str, Any]) -> Tuple[List[Document], Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Load and process company filings from URLs.\n",
        "\n",
        "    Args:\n",
        "        urls: List of tuples (company_name, url)\n",
        "        config: Configuration dictionary\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (processed_chunks, director_sections)\n",
        "    \"\"\"\n",
        "    processed_chunks = []\n",
        "    director_sections = {}\n",
        "\n",
        "    # Create text splitter\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=config[\"chunkSize\"],\n",
        "        chunk_overlap=config[\"chunkOverlap\"]\n",
        "    )\n",
        "\n",
        "    for company, url in urls:\n",
        "        try:\n",
        "            print(f\"Loading {company} filing from {url}\")\n",
        "\n",
        "            # Load document using WebBaseLoader\n",
        "            loader = WebBaseLoader(\n",
        "                url,\n",
        "                header_template={'User-Agent': config[\"userAgentHeader\"]}\n",
        "            )\n",
        "            docs = loader.load()\n",
        "\n",
        "            # Store last 1000 characters for director extraction\n",
        "            if docs and len(docs) > 0:\n",
        "                director_sections[company] = docs[0].page_content[-1000:]\n",
        "\n",
        "            # Split documents into chunks\n",
        "            chunks = splitter.transform_documents(docs)\n",
        "\n",
        "            # Add company metadata to each chunk\n",
        "            for chunk in chunks:\n",
        "                chunk.metadata[\"company\"] = company\n",
        "\n",
        "            processed_chunks.extend(chunks)\n",
        "            print(f\"Processed {len(chunks)} chunks from {company}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {company} from {url}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"Total processed chunks: {len(processed_chunks)}\")\n",
        "    return processed_chunks, director_sections"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40f18f88",
      "metadata": {
        "id": "40f18f88"
      },
      "source": [
        "# Vector Store & Retriever — Embeddings, FAISS, and Reranking\n",
        "\n",
        "Overview\n",
        "- Create embeddings for each chunk using an embedding model (OpenAI).\n",
        "- Store vectors in FAISS for efficient similarity search.\n",
        "- Use a reranker (Flashrank) to re-score the top-k search results for higher relevance.\n",
        "\n",
        "Why rerank?\n",
        "- Initial vector similarity finds semantically close chunks, but results can include noisy matches.\n",
        "- A lightweight reranker (supervised or distilled model) improves the ordering of candidate documents before passing them as context to the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c1bca2c",
      "metadata": {
        "id": "1c1bca2c"
      },
      "outputs": [],
      "source": [
        "def create_vector_store(chunks: List[Document], config: Dict[str, Any]) -> FAISS:\n",
        "    \"\"\"\n",
        "    Create a FAISS vector store with OpenAI embeddings.\n",
        "\n",
        "    Args:\n",
        "        chunks: List of document chunks\n",
        "        config: Configuration dictionary\n",
        "\n",
        "    Returns:\n",
        "        FAISS vector store\n",
        "    \"\"\"\n",
        "    print(\"Creating vector store with OpenAI embeddings...\")\n",
        "\n",
        "    # Create embedding function\n",
        "    embedding_function = OpenAIEmbeddings(\n",
        "        model=config[\"embeddingModelName\"]\n",
        "    )\n",
        "\n",
        "    # Create FAISS vector store\n",
        "    vectorstore = FAISS.from_documents(chunks, embedding_function)\n",
        "\n",
        "    print(f\"Vector store created successfully\")\n",
        "    print(f\"Number of vectors: {vectorstore.index.ntotal}\")\n",
        "    print(f\"Vector dimension: {vectorstore.index.d}\")\n",
        "\n",
        "    return vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ktzPLXeJ5Ehs",
      "metadata": {
        "id": "ktzPLXeJ5Ehs"
      },
      "outputs": [],
      "source": [
        "def create_retriever_with_reranking(vectorstore: FAISS, config: Dict[str, Any]):\n",
        "    \"\"\"\n",
        "    Create a retriever with Flashrank reranking.\n",
        "\n",
        "    Args:\n",
        "        vectorstore: FAISS vector store\n",
        "        config: Configuration dictionary\n",
        "\n",
        "    Returns:\n",
        "        ContextualCompressionRetriever with reranking\n",
        "    \"\"\"\n",
        "    print(\"Creating retriever with Flashrank reranking...\")\n",
        "\n",
        "    # Create base retriever\n",
        "    base_retriever = vectorstore.as_retriever(\n",
        "        search_kwargs={\"k\": config[\"numRetrievedDocuments\"]}\n",
        "    )\n",
        "\n",
        "    # Create Flashrank reranker\n",
        "    model_name = config[\"rerankerModel\"]\n",
        "    top_n = config[\"numRerankedDocuments\"]\n",
        "\n",
        "    ranker_client = Ranker(model_name=model_name)\n",
        "    reranker = FlashrankRerank(client=ranker_client, model=model_name, top_n=top_n)\n",
        "\n",
        "    # Create compression retriever with reranker\n",
        "    compression_retriever = ContextualCompressionRetriever(\n",
        "        base_retriever=base_retriever,\n",
        "        base_compressor=reranker\n",
        "    )\n",
        "\n",
        "    print(\"Retriever with reranking created successfully\")\n",
        "    return compression_retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b03e8f3d",
      "metadata": {
        "id": "b03e8f3d"
      },
      "source": [
        "# Custom Tools for the ReAct Agent\n",
        "\n",
        "We implement three tools used by the agent:\n",
        "1. CompanyDirectorsTool — extracts board/director names from filings and optionally finds LinkedIn profiles.\n",
        "2. WebSearchTool — performs web searches (SerpAPI) to gather current information.\n",
        "3. VectorRerankerSearchTool — queries the vector store and returns reranked document snippets.\n",
        "\n",
        "Design considerations\n",
        "- Each tool should return concise, machine- and human-readable output.\n",
        "- Tools are wrapped to keep the agent's core LLM stateless and auditable.\n",
        "- Cache external lookups (e.g., LinkedIn) to reduce API usage and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da8c75a5",
      "metadata": {
        "id": "da8c75a5"
      },
      "outputs": [],
      "source": [
        "# Cache for LinkedIn lookups to avoid repeated API calls\n",
        "linkedin_cache = {}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa50d7e1",
      "metadata": {
        "id": "fa50d7e1"
      },
      "source": [
        "### Company Directors Tool — Input & Output\n",
        "\n",
        "Purpose\n",
        "- Extracts names of company directors from a provided text snippet.\n",
        "- Optionally searches for LinkedIn profile URLs for each director.\n",
        "\n",
        "Input format\n",
        "- `company_name, true|false` (true to include LinkedIn handles).\n",
        "\n",
        "Output\n",
        "- A comma- or semicolon-separated list of names, optionally with LinkedIn URLs.\n",
        "\n",
        "Privacy & legal note\n",
        "- Scraping or programmatically collecting personal profile URLs may be subject to terms of service and privacy laws. Use responsibly and respect rate limits and robot policies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb6352ca",
      "metadata": {
        "id": "bb6352ca"
      },
      "outputs": [],
      "source": [
        "class CompanyDirectorsTool(BaseTool):\n",
        "    \"\"\"Tool to retrieve company director names and LinkedIn profiles.\"\"\"\n",
        "\n",
        "    name: str = \"Company Directors Information\"\n",
        "    description: str = \"Retrieve the names of company directors for a chosen company. Optionally, their LinkedIn handles can also be included. Use the format: company_name, true/false.\"\n",
        "\n",
        "    # Custom attributes\n",
        "    director_sections: Dict[str, str] = {}\n",
        "    config: Dict[str, Any] = {}\n",
        "\n",
        "    def __init__(self, director_sections: Dict[str, str], config: Dict[str, Any]):\n",
        "        \"\"\"Initialize the tool with director sections and config.\"\"\"\n",
        "        # Update description with available companies\n",
        "        available_companies = list(director_sections.keys())\n",
        "        updated_description = f\"{config['directorToolDescription']} Available companies: {', '.join(available_companies)}\"\n",
        "\n",
        "        super().__init__(\n",
        "            director_sections=director_sections,\n",
        "            config=config,\n",
        "            description=updated_description\n",
        "        )\n",
        "\n",
        "    def _run(self, query: str) -> str:\n",
        "        \"\"\"Execute the tool to get director information.\"\"\"\n",
        "        try:\n",
        "            # Parse input\n",
        "            parts = query.split(',')\n",
        "            company_name = parts[0].strip()\n",
        "            include_linkedin = parts[1].strip().lower() == 'true' if len(parts) > 1 else True\n",
        "\n",
        "            # Get director section\n",
        "            company_snippet = self.director_sections.get(company_name)\n",
        "            if not company_snippet:\n",
        "                return f\"No director information found for {company_name}\"\n",
        "\n",
        "            # Extract director names using LLM\n",
        "            director_names = self._extract_director_names(company_snippet)\n",
        "\n",
        "            if not director_names:\n",
        "                return f\"Could not extract director names for {company_name}\"\n",
        "\n",
        "            # Get LinkedIn handles if requested\n",
        "            if include_linkedin:\n",
        "                director_handles = []\n",
        "                for name in director_names:\n",
        "                    linkedin_handle = self._get_linkedin_handle(name, company_name)\n",
        "                    director_handles.append(f\"{name} (LinkedIn: {linkedin_handle})\")\n",
        "\n",
        "                return f\"Directors of {company_name}: {'; '.join(director_handles)}\"\n",
        "            else:\n",
        "                return f\"Directors of {company_name}: {', '.join(director_names)}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error retrieving director information: {str(e)}\"\n",
        "\n",
        "    def _extract_director_names(self, text: str) -> List[str]:\n",
        "        \"\"\"Extract director names from text using LLM.\"\"\"\n",
        "        try:\n",
        "            llm = ChatOpenAI(\n",
        "                model=self.config[\"nameExtractionModel\"],\n",
        "                temperature=self.config[\"nameExtractionModelTemperature\"]\n",
        "            )\n",
        "            parser = CommaSeparatedListOutputParser()\n",
        "            prompt = PromptTemplate.from_template(self.config[\"nameExtractionPrompt\"])\n",
        "\n",
        "            chain = prompt | llm | parser\n",
        "            names = chain.invoke({\"text\": text})\n",
        "            return names\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting names: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def _get_linkedin_handle(self, name: str, company: str) -> str:\n",
        "        \"\"\"Get LinkedIn handle for a director.\"\"\"\n",
        "        cache_key = f\"{name}_{company}\"\n",
        "\n",
        "        # Check cache first\n",
        "        if cache_key in linkedin_cache:\n",
        "            return linkedin_cache[cache_key]\n",
        "\n",
        "        try:\n",
        "            # Use SerpAPI to search LinkedIn\n",
        "            search = SerpAPIWrapper()\n",
        "            results = search.results(f'\"{name}\" {company} site:linkedin.com/in/')\n",
        "\n",
        "            # Extract link from results\n",
        "            link = results.get(\"organic_results\", [{}])[0].get(\"link\", \"Profile not found\")\n",
        "\n",
        "            # Cache the result\n",
        "            linkedin_cache[cache_key] = link\n",
        "            return link\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error finding LinkedIn profile: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BrKa6O_1vSik",
      "metadata": {
        "id": "BrKa6O_1vSik"
      },
      "outputs": [],
      "source": [
        "class WebSearchTool(BaseTool):\n",
        "    \"\"\"Tool to perform web searches using SerpAPI.\"\"\"\n",
        "\n",
        "    name: str = \"WebSearch\"\n",
        "    description: str = \"Performs a web search on the query.\"\n",
        "\n",
        "    # Custom attributes\n",
        "    config: Dict[str, Any] = {}\n",
        "\n",
        "    def __init__(self, config: Dict[str, Any]):\n",
        "        \"\"\"Initialize the tool with configuration.\"\"\"\n",
        "        super().__init__(config=config)\n",
        "\n",
        "    def _run(self, query: str) -> str:\n",
        "        \"\"\"Execute the web search.\"\"\"\n",
        "        try:\n",
        "            search = SerpAPIWrapper()\n",
        "            results = search.results(query)\n",
        "            return self._format_results(results)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error performing web search: {str(e)}\"\n",
        "\n",
        "    def _format_results(self, results: Dict) -> str:\n",
        "        \"\"\"Format search results into readable text.\"\"\"\n",
        "        formatted = []\n",
        "        num_results = self.config[\"numWebToolResults\"]\n",
        "\n",
        "        for result in results.get(\"organic_results\", [])[:num_results]:\n",
        "            formatted.append(\n",
        "                f\"Title: {result.get('title', 'N/A')}\\n\"\n",
        "                f\"Snippet: {result.get('snippet', 'N/A')}\\n\"\n",
        "                f\"Link: {result.get('link', 'N/A')}\"\n",
        "            )\n",
        "\n",
        "        return \"\\n\\n\".join(formatted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PAIF2yw5vTVN",
      "metadata": {
        "id": "PAIF2yw5vTVN"
      },
      "outputs": [],
      "source": [
        "class VectorRerankerSearchTool(BaseTool):\n",
        "    \"\"\"Tool to search the vector database with reranking.\"\"\"\n",
        "\n",
        "    name: str = \"Vector Reranker Search\"\n",
        "    description: str = \"Retrieves information from an embedding based vector DB containing financial data and company information. Structure query as a sentence.\"\n",
        "\n",
        "    # Custom attributes\n",
        "    retriever: Any = None\n",
        "    config: Dict[str, Any] = {}\n",
        "\n",
        "    def __init__(self, retriever: Any, config: Dict[str, Any]):\n",
        "        \"\"\"Initialize the tool with retriever and config.\"\"\"\n",
        "        super().__init__(retriever=retriever, config=config)\n",
        "\n",
        "    def _run(self, query: str) -> str:\n",
        "        \"\"\"Execute the vector search with reranking.\"\"\"\n",
        "        try:\n",
        "            # Retrieve documents\n",
        "            docs = self.retriever.invoke(query)\n",
        "\n",
        "            # Format and return top results\n",
        "            num_results = self.config[\"numRetrieverToolResults\"]\n",
        "            formatted_docs = []\n",
        "\n",
        "            for doc in docs[:num_results]:\n",
        "                company = doc.metadata.get('company', '')\n",
        "                content = doc.page_content\n",
        "                formatted_docs.append(f\"{company}\\n{content}\")\n",
        "\n",
        "            return \"\\n\\n\".join(formatted_docs)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error retrieving documents: {str(e)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b58927ac",
      "metadata": {
        "id": "b58927ac"
      },
      "source": [
        "# Agent Setup Functions — Composition & Lifecycle\n",
        "\n",
        "This section defines helper functions to:\n",
        "- Create tool instances based on configuration and available resources.\n",
        "- Assemble those tools into the ReAct agent.\n",
        "- Return an `AgentExecutor` that orchestrates tool calls and LLM reasoning.\n",
        "\n",
        "Guidance\n",
        "- Tools should be tested individually before composing into the agent.\n",
        "- Keep tool interfaces simple and predictable to make agent reasoning clearer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "373e7c78",
      "metadata": {
        "id": "373e7c78"
      },
      "outputs": [],
      "source": [
        "def create_tools(config: Dict[str, Any], director_sections: Dict[str, str], retriever) -> List[BaseTool]:\n",
        "    \"\"\"\n",
        "    Create all tools for the ReAct agent.\n",
        "\n",
        "    Args:\n",
        "        config: Configuration dictionary\n",
        "        director_sections: Dictionary mapping company names to director text sections\n",
        "        retriever: Retriever with reranking\n",
        "\n",
        "    Returns:\n",
        "        List of tools\n",
        "    \"\"\"\n",
        "    tools = []\n",
        "\n",
        "    # Add Company Directors Tool\n",
        "    if config.get(\"useDirectorTool\", False):\n",
        "        director_tool = CompanyDirectorsTool(director_sections, config)\n",
        "        tools.append(director_tool)\n",
        "        print(f\"Added tool: {director_tool.name}\")\n",
        "\n",
        "    # Add Web Search Tool\n",
        "    if config.get(\"useWebTool\", False):\n",
        "        web_tool = WebSearchTool(config)\n",
        "        tools.append(web_tool)\n",
        "        print(f\"Added tool: {web_tool.name}\")\n",
        "\n",
        "    # Add Vector Reranker Search Tool\n",
        "    if config.get(\"useRetrieverTool\", False):\n",
        "        retriever_tool = VectorRerankerSearchTool(retriever, config)\n",
        "        tools.append(retriever_tool)\n",
        "        print(f\"Added tool: {retriever_tool.name}\")\n",
        "\n",
        "    print(f\"Total tools created: {len(tools)}\")\n",
        "    return tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_E-ZmzFQvim7",
      "metadata": {
        "id": "_E-ZmzFQvim7"
      },
      "outputs": [],
      "source": [
        "def create_react_agent_executor(tools: List[BaseTool], config: Dict[str, Any]) -> AgentExecutor:\n",
        "    \"\"\"\n",
        "    Create a ReAct agent executor with the specified tools.\n",
        "\n",
        "    Args:\n",
        "        tools: List of tools for the agent\n",
        "        config: Configuration dictionary\n",
        "\n",
        "    Returns:\n",
        "        AgentExecutor\n",
        "    \"\"\"\n",
        "    print(\"Creating ReAct agent...\")\n",
        "\n",
        "    # Create LLM for the agent\n",
        "    llm = ChatOpenAI(\n",
        "        model=config[\"reactModelName\"],\n",
        "        temperature=config[\"reactModelTemperature\"]\n",
        "    )\n",
        "\n",
        "    # Create prompt template\n",
        "    prompt = PromptTemplate.from_template(config[\"reactPromptTemplate\"])\n",
        "\n",
        "    # Create ReAct agent\n",
        "    agent = create_react_agent(llm, tools, prompt)\n",
        "\n",
        "    # Create agent executor\n",
        "    agent_executor = AgentExecutor(\n",
        "        agent=agent,\n",
        "        tools=tools,\n",
        "        verbose=config.get(\"reactVerbosity\", True),\n",
        "        handle_parsing_errors=True\n",
        "    )\n",
        "\n",
        "    print(\"ReAct agent created successfully\")\n",
        "    return agent_executor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1792a79d",
      "metadata": {
        "id": "1792a79d"
      },
      "source": [
        "# Main Execution Flow — Step-by-step pipeline\n",
        "\n",
        "This cell runs the full pipeline in a reproducible order:\n",
        "1. Load and process source documents (SEC filings).\n",
        "2. Build a FAISS vector store from processed chunks.\n",
        "3. Create a retriever with reranking capability.\n",
        "4. Instantiate tools (directors, web search, vector reranker).\n",
        "5. Create a ReAct agent executor with the tools and a prompt template.\n",
        "6. Invoke the agent on a complex, multi-part query.\n",
        "\n",
        "Notes for running\n",
        "- Running end-to-end requires network access and valid API keys.\n",
        "- For debugging, run earlier steps (e.g., vector store creation) independently and inspect outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8053bbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8053bbc",
        "outputId": "0c478729-2c61-4608-e952-e24894670e16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "STEP 1: Loading and Processing Documents\n",
            "============================================================\n",
            "Loading Tesla filing from https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm\n",
            "Processed 942 chunks from Tesla\n",
            "Loading General Motors filing from https://www.sec.gov/Archives/edgar/data/1467858/000146785824000031/gm-20231231.htm\n",
            "Processed 1085 chunks from General Motors\n",
            "Total processed chunks: 2027\n",
            "\n",
            "============================================================\n",
            "STEP 2: Creating Vector Store\n",
            "============================================================\n",
            "Creating vector store with OpenAI embeddings...\n",
            "Vector store created successfully\n",
            "Number of vectors: 2027\n",
            "Vector dimension: 1536\n",
            "\n",
            "============================================================\n",
            "STEP 3: Creating Retriever with Reranking\n",
            "============================================================\n",
            "Creating retriever with Flashrank reranking...\n",
            "Retriever with reranking created successfully\n",
            "\n",
            "============================================================\n",
            "STEP 4: Creating Tools for Agent\n",
            "============================================================\n",
            "Added tool: Company Directors Information\n",
            "Added tool: WebSearch\n",
            "Added tool: Vector Reranker Search\n",
            "Total tools created: 3\n",
            "\n",
            "============================================================\n",
            "STEP 5: Creating ReAct Agent\n",
            "============================================================\n",
            "Creating ReAct agent...\n",
            "ReAct agent created successfully\n",
            "\n",
            "============================================================\n",
            "STEP 6: Running Agent with Complex Query\n",
            "============================================================\n",
            "\n",
            "Question: Who are the directors of Tesla. What are their linkedin handles? What are the financial goals of tesla this year. What is the next auto show that Tesla will participate in.\n",
            "\n",
            "Agent is working...\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo answer the question, I need to gather information on the directors of Tesla, their LinkedIn handles, Tesla's financial goals for this year, and the next auto show Tesla will participate in.\n",
            "\n",
            "First, I'll start by finding the directors of Tesla and their LinkedIn handles.\n",
            "\n",
            "Action: Company Directors Information\n",
            "Action Input: Tesla, true\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mDirectors of Tesla: Elon Musk (LinkedIn: https://www.linkedin.com/in/elon-musk-tesla-company-b7b00879); Robyn Denholm (LinkedIn: https://au.linkedin.com/in/robyn-denholm-a807795); Ira Ehrenpreis (LinkedIn: https://www.linkedin.com/in/iraehrenpreis); Joseph Gebbia (LinkedIn: Profile not found); James Murdoch (LinkedIn: https://www.linkedin.com/in/jamesrmurdoch); Kimbal Musk (LinkedIn: https://www.linkedin.com/in/kimbal); JB Straubel (LinkedIn: https://www.linkedin.com/in/jb-straubel-b694981); Kathleen Wilson-Thompson (LinkedIn: https://www.linkedin.com/in/kathleen-wilson-thompson-275654201)\u001b[0m\u001b[32;1m\u001b[1;3mI have obtained the names and LinkedIn handles of the directors of Tesla. Next, I need to find information about Tesla's financial goals for this year.\n",
            "\n",
            "Action: Vector Reranker Search\n",
            "Action Input: What are Tesla's financial goals for this year?\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3mTesla\n",
            "consolidated balance sheets of Tesla, Inc. and its subsidiaries (the “Company”) as of December 31, 2023 and 2022, and the related consolidated statements of operations, of comprehensive income, of redeemable noncontrolling interests and equity and of cash flows for each of the three years in the period ended December 31, 2023, including the related notes (collectively referred to as the “consolidated financial statements”). We also have audited the Company's internal control over financial\n",
            "\n",
            "Tesla\n",
            "which oversees our ESG impacts, initiatives and priorities.Human Capital ResourcesA competitive edge for Tesla is its ability to attract and retain high quality employees. During the past year, Tesla made substantial investments in its workforce, further strengthening its standing as one of the most desirable and innovative companies to work for. As of December 31, 2023, our employee headcount worldwide was 140,473.We have created an environment that fosters growth opportunities, and as of this\n",
            "\n",
            "Tesla\n",
            "long-term liabilities— 3 Total liabilities$3,777 $2,215 Note 17 – Related Party TransactionsIn relation to our CEO’s exercise of stock options and sale of common stock from the 2012 CEO Performance Award, Tesla withheld the appropriate amount of taxes. However, given the significant amounts involved, our CEO entered into an indemnification agreement with us in November 2021 for additional taxes owed, if any. Tesla periodically does business with certain entities with which its CEO and directors\u001b[0m\u001b[32;1m\u001b[1;3mI have gathered some financial information about Tesla, but it doesn't specifically address their financial goals for this year. I need to perform a more targeted search to find Tesla's financial goals for 2023.\n",
            "\n",
            "Action: WebSearch\n",
            "Action Input: Tesla financial goals 2023\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mTitle: Tesla Full Year 2023 Analysis — A Review of Actual ...\n",
            "Snippet: Tesla earned $13.2 billion in Operating Cash Flow and $4.3 billion in Free Cash Flow in 2023, spending $8.9 billion on Capital Expenditure. The ...\n",
            "Link: https://medium.com/@nambos3rd/tesla-full-year-2023-analysis-a-review-of-actual-performance-my-financial-forecast-579771d7d452\n",
            "\n",
            "Title: Tesla's 2023 Impact Report\n",
            "Snippet: In addition, we aim to transition our operational electricity load to 100% renewables well before we achieve our net-zero emissions goal and to continue.\n",
            "Link: https://www.tesla.com/ns_videos/2023-tesla-impact-report-highlights.pdf\n",
            "\n",
            "Title: tsla-20231231-gen.pdf\n",
            "Snippet: We also have audited the Company's internal control over financial reporting as of December 31, 2023, based on criteria established in.\n",
            "Link: https://ir.tesla.com/_flysystem/s3/sec/000162828024002390/tsla-20231231-gen.pdf\u001b[0m\u001b[32;1m\u001b[1;3mI have found some information regarding Tesla's financial performance in 2023, but I still need to find specific financial goals for the year. I will now search for the next auto show Tesla will participate in.\n",
            "\n",
            "Action: WebSearch\n",
            "Action Input: Tesla next auto show participation 2023\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mTitle: Tesla will participate in 2023 Munich auto show\n",
            "Snippet: Tesla joins German automakers taking part in the show, along with Chinese brands including BYD, FAW's Hongqi brand, Leapmotor, Seres and ...\n",
            "Link: https://www.autonews.com/munich-auto-show/tesla-will-participate-2023-munich-auto-show/\n",
            "\n",
            "Title: Everything that stood out to us at the 2023 New York Auto ...\n",
            "Snippet: The 2023 New York International Auto Show was all about EVs, software, and big trucks and SUVs. Find out what stood out to TechCrunch.\n",
            "Link: https://techcrunch.com/2023/04/06/everything-that-stood-out-to-us-at-the-2023-new-york-auto-show/\n",
            "\n",
            "Title: Tesla to Join 2023 Detroit Auto Show\n",
            "Snippet: Tesla will join the 2023 Detroit Auto Show that will take place September 13-24. The company will showcase its vehicles at the Powering ...\n",
            "Link: https://driveteslacanada.ca/news/tesla-to-join-2023-detroit-auto-show/\u001b[0m\u001b[32;1m\u001b[1;3mI have gathered the necessary information to answer the question.\n",
            "\n",
            "Final Answer: The directors of Tesla are Elon Musk, Robyn Denholm, Ira Ehrenpreis, Joseph Gebbia, James Murdoch, Kimbal Musk, JB Straubel, and Kathleen Wilson-Thompson. Their LinkedIn handles are as follows:\n",
            "- Elon Musk: [LinkedIn](https://www.linkedin.com/in/elon-musk-tesla-company-b7b00879)\n",
            "- Robyn Denholm: [LinkedIn](https://au.linkedin.com/in/robyn-denholm-a807795)\n",
            "- Ira Ehrenpreis: [LinkedIn](https://www.linkedin.com/in/iraehrenpreis)\n",
            "- Joseph Gebbia: LinkedIn profile not found\n",
            "- James Murdoch: [LinkedIn](https://www.linkedin.com/in/jamesrmurdoch)\n",
            "- Kimbal Musk: [LinkedIn](https://www.linkedin.com/in/kimbal)\n",
            "- JB Straubel: [LinkedIn](https://www.linkedin.com/in/jb-straubel-b694981)\n",
            "- Kathleen Wilson-Thompson: [LinkedIn](https://www.linkedin.com/in/kathleen-wilson-thompson-275654201)\n",
            "\n",
            "Tesla's financial goals for 2023 include transitioning their operational electricity load to 100% renewables well before achieving their net-zero emissions goal.\n",
            "\n",
            "The next auto show Tesla will participate in is the 2023 Munich Auto Show.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "============================================================\n",
            "FINAL ANSWER\n",
            "============================================================\n",
            "The directors of Tesla are Elon Musk, Robyn Denholm, Ira Ehrenpreis, Joseph Gebbia, James Murdoch, Kimbal Musk, JB Straubel, and Kathleen Wilson-Thompson. Their LinkedIn handles are as follows:\n",
            "- Elon Musk: [LinkedIn](https://www.linkedin.com/in/elon-musk-tesla-company-b7b00879)\n",
            "- Robyn Denholm: [LinkedIn](https://au.linkedin.com/in/robyn-denholm-a807795)\n",
            "- Ira Ehrenpreis: [LinkedIn](https://www.linkedin.com/in/iraehrenpreis)\n",
            "- Joseph Gebbia: LinkedIn profile not found\n",
            "- James Murdoch: [LinkedIn](https://www.linkedin.com/in/jamesrmurdoch)\n",
            "- Kimbal Musk: [LinkedIn](https://www.linkedin.com/in/kimbal)\n",
            "- JB Straubel: [LinkedIn](https://www.linkedin.com/in/jb-straubel-b694981)\n",
            "- Kathleen Wilson-Thompson: [LinkedIn](https://www.linkedin.com/in/kathleen-wilson-thompson-275654201)\n",
            "\n",
            "Tesla's financial goals for 2023 include transitioning their operational electricity load to 100% renewables well before achieving their net-zero emissions goal.\n",
            "\n",
            "The next auto show Tesla will participate in is the 2023 Munich Auto Show.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load and process documents\n",
        "print(\"=\" * 60)\n",
        "print(\"STEP 1: Loading and Processing Documents\")\n",
        "print(\"=\" * 60)\n",
        "processed_chunks, director_sections = load_and_process_filings(\n",
        "    config[\"companyFilingUrls\"],\n",
        "    config\n",
        ")\n",
        "\n",
        "# Step 2: Create vector store\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 2: Creating Vector Store\")\n",
        "print(\"=\" * 60)\n",
        "vectorstore = create_vector_store(processed_chunks, config)\n",
        "\n",
        "# Step 3: Create retriever with reranking\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 3: Creating Retriever with Reranking\")\n",
        "print(\"=\" * 60)\n",
        "retriever = create_retriever_with_reranking(vectorstore, config)\n",
        "\n",
        "# Step 4: Create tools\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 4: Creating Tools for Agent\")\n",
        "print(\"=\" * 60)\n",
        "tools = create_tools(config, director_sections, retriever)\n",
        "\n",
        "# Step 5: Create ReAct agent\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 5: Creating ReAct Agent\")\n",
        "print(\"=\" * 60)\n",
        "agent_executor = create_react_agent_executor(tools, config)\n",
        "\n",
        "# Step 6: Ask a complex question\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 6: Running Agent with Complex Query\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "question = \"Who are the directors of Tesla. What are their linkedin handles? What are the financial goals of tesla this year. What is the next auto show that Tesla will participate in.\"\n",
        "\n",
        "print(f\"\\nQuestion: {question}\\n\")\n",
        "print(\"Agent is working...\\n\")\n",
        "\n",
        "response = agent_executor.invoke({\"input\": question})\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FINAL ANSWER\")\n",
        "print(\"=\" * 60)\n",
        "print(response['output'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6g2OEs5wnUXc",
      "metadata": {
        "id": "6g2OEs5wnUXc"
      },
      "source": [
        "Tools, Memory, Planning — core agent components\n",
        "\n",
        "- **Tools**: External actions the agent can call to gather evidence (search, retrieval, special parsers).\n",
        "- **Memory**: Long- or short-term state the agent may use to persist context across turns (not heavily used here).\n",
        "- **Planning**: The agent's internal reasoning that decides which tools to call and in what order (ReAct's Thought/Action loop).\n",
        "\n",
        "Why these matter\n",
        "- Combining tools with internal planning enables the agent to mix retrieval, external data, and chain-of-thought to solve complex tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XcRWj2lYnc-Y",
      "metadata": {
        "id": "XcRWj2lYnc-Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "54e2db0f",
      "metadata": {
        "id": "54e2db0f"
      },
      "source": [
        "# Task: Implement token and cost tracking for agent runs\n",
        "\n",
        "Goal\n",
        "- Add a helper function `calculate_agent_tokens_and_cost(agent_executor, question)` that uses `langchain.callbacks.get_openai_callback` to capture token usage and estimated cost for a single agent invocation.\n",
        "\n",
        "Expected behavior\n",
        "- Wrap `agent_executor.invoke()` with `get_openai_callback()` context manager.\n",
        "- Return or print the `total_tokens` and `total_cost` captured by the callback.\n",
        "- Provide a short example invocation and print the final report."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "627f659b",
      "metadata": {
        "id": "627f659b"
      },
      "source": [
        "## Implement Token and Cost Calculation Function — Details\n",
        "\n",
        "Subtasks\n",
        "1. Import `get_openai_callback` from LangChain callbacks module.\n",
        "2. Define `calculate_agent_tokens_and_cost`:\n",
        "    - Use `with get_openai_callback() as cb: agent_executor.invoke({\"input\": question})`\n",
        "    - Retrieve `cb.total_tokens` and `cb.total_cost`.\n",
        "3. Call the function with a sample question and print a formatted report.\n",
        "\n",
        "Caveats\n",
        "- Callback only tracks OpenAI API calls made through LangChain's OpenAI wrappers.\n",
        "- If the agent triggers other non-OpenAI network calls (e.g., SerpAPI), these are not counted in this token estimate."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc03248",
      "metadata": {
        "id": "1bc03248"
      },
      "source": [
        "**Reasoning**\n",
        "\n",
        "When running token/cost measurement, ensure the `agent_executor` and its dependent resources (vector store, retriever, tools) are available in the current runtime. In interactive environments the notebook kernel may have lost prior state; re-run setup cells or instantiate components in the same cell before measurement.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cb662ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cb662ec",
        "outputId": "18c93793-8e3e-486f-efb1-b7e05c3d58b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function `calculate_agent_tokens_and_cost` defined.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.callbacks import get_openai_callback\n",
        "\n",
        "def calculate_agent_tokens_and_cost(agent_executor, question: str):\n",
        "    \"\"\"\n",
        "    Calculates the total tokens used and estimated cost for an agent's execution.\n",
        "\n",
        "    Args:\n",
        "        agent_executor: The LangChain AgentExecutor instance.\n",
        "        question: The input question for the agent.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing (total_tokens, estimated_cost).\n",
        "    \"\"\"\n",
        "    total_tokens = 0\n",
        "    estimated_cost = 0.0\n",
        "\n",
        "    with get_openai_callback() as cb:\n",
        "        agent_executor.invoke({\"input\": question})\n",
        "        total_tokens = cb.total_tokens\n",
        "        estimated_cost = cb.total_cost\n",
        "\n",
        "    return total_tokens, estimated_cost\n",
        "\n",
        "print(\"Function `calculate_agent_tokens_and_cost` defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5c65a85",
      "metadata": {
        "id": "d5c65a85"
      },
      "source": [
        "**Reasoning — reinitialization approach**\n",
        "\n",
        "If a previous run failed due to missing objects, re-create the pipeline in the same cell:\n",
        "- Rebuild processed chunks, vectorstore, retriever, tools, and agent executor.\n",
        "- Then call `calculate_agent_tokens_and_cost` to capture token usage reliably.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9544b116",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9544b116",
        "outputId": "fba89593-3ed5-4247-cdaf-e7078a0d2c11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Tesla filing from https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm\n",
            "Processed 942 chunks from Tesla\n",
            "Loading General Motors filing from https://www.sec.gov/Archives/edgar/data/1467858/000146785824000031/gm-20231231.htm\n",
            "Processed 1085 chunks from General Motors\n",
            "Total processed chunks: 2027\n",
            "Creating vector store with OpenAI embeddings...\n",
            "Vector store created successfully\n",
            "Number of vectors: 2027\n",
            "Vector dimension: 1536\n",
            "Creating retriever with Flashrank reranking...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ms-marco-TinyBERT-L-2-v2.zip: 100%|██████████| 3.26M/3.26M [00:00<00:00, 109MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retriever with reranking created successfully\n",
            "Added tool: Company Directors Information\n",
            "Added tool: WebSearch\n",
            "Added tool: Vector Reranker Search\n",
            "Total tools created: 3\n",
            "Creating ReAct agent...\n",
            "ReAct agent created successfully\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo answer the question, I need to gather information on the directors of Tesla, their LinkedIn handles, Tesla's financial goals for this year, and the next auto show Tesla will participate in.\n",
            "\n",
            "Action: Company Directors Information\n",
            "\n",
            "Action Input: Tesla, true\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mDirectors of Tesla: Elon Musk (LinkedIn: https://www.linkedin.com/in/elon-musk-tesla-company-b7b00879); Robyn Denholm (LinkedIn: https://au.linkedin.com/in/robyn-denholm-a807795); Ira Ehrenpreis (LinkedIn: https://www.linkedin.com/in/iraehrenpreis); Joseph Gebbia (LinkedIn: Profile not found); James Murdoch (LinkedIn: https://www.linkedin.com/in/jamesrmurdoch); Kimbal Musk (LinkedIn: https://www.linkedin.com/in/kimbal); JB Straubel (LinkedIn: https://www.linkedin.com/in/jb-straubel-b694981); Kathleen Wilson-Thompson (LinkedIn: https://www.linkedin.com/in/kathleen-wilson-thompson-275654201)\u001b[0m\u001b[32;1m\u001b[1;3mI have obtained the names and LinkedIn handles of Tesla's directors. Next, I need to find information about Tesla's financial goals for this year.\n",
            "\n",
            "Action: Vector Reranker Search\n",
            "\n",
            "Action Input: What are Tesla's financial goals for this year?\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3mTesla\n",
            "consolidated balance sheets of Tesla, Inc. and its subsidiaries (the “Company”) as of December 31, 2023 and 2022, and the related consolidated statements of operations, of comprehensive income, of redeemable noncontrolling interests and equity and of cash flows for each of the three years in the period ended December 31, 2023, including the related notes (collectively referred to as the “consolidated financial statements”). We also have audited the Company's internal control over financial\n",
            "\n",
            "Tesla\n",
            "which oversees our ESG impacts, initiatives and priorities.Human Capital ResourcesA competitive edge for Tesla is its ability to attract and retain high quality employees. During the past year, Tesla made substantial investments in its workforce, further strengthening its standing as one of the most desirable and innovative companies to work for. As of December 31, 2023, our employee headcount worldwide was 140,473.We have created an environment that fosters growth opportunities, and as of this\n",
            "\n",
            "Tesla\n",
            "long-term liabilities— 3 Total liabilities$3,777 $2,215 Note 17 – Related Party TransactionsIn relation to our CEO’s exercise of stock options and sale of common stock from the 2012 CEO Performance Award, Tesla withheld the appropriate amount of taxes. However, given the significant amounts involved, our CEO entered into an indemnification agreement with us in November 2021 for additional taxes owed, if any. Tesla periodically does business with certain entities with which its CEO and directors\u001b[0m\u001b[32;1m\u001b[1;3mI have gathered some financial information about Tesla, but it doesn't specifically address their financial goals for this year. I need to perform a more targeted search to find Tesla's financial goals for 2023.\n",
            "\n",
            "Action: WebSearch\n",
            "\n",
            "Action Input: Tesla financial goals 2023\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mTitle: Tesla Full Year 2023 Analysis — A Review of Actual ...\n",
            "Snippet: Tesla earned $13.2 billion in Operating Cash Flow and $4.3 billion in Free Cash Flow in 2023, spending $8.9 billion on Capital Expenditure. The ...\n",
            "Link: https://medium.com/@nambos3rd/tesla-full-year-2023-analysis-a-review-of-actual-performance-my-financial-forecast-579771d7d452\n",
            "\n",
            "Title: Tesla's 2023 Impact Report\n",
            "Snippet: In addition, we aim to transition our operational electricity load to 100% renewables well before we achieve our net-zero emissions goal and to continue.\n",
            "Link: https://www.tesla.com/ns_videos/2023-tesla-impact-report-highlights.pdf\n",
            "\n",
            "Title: tsla-20231231-gen.pdf\n",
            "Snippet: We also have audited the Company's internal control over financial reporting as of December 31, 2023, based on criteria established in.\n",
            "Link: https://ir.tesla.com/_flysystem/s3/sec/000162828024002390/tsla-20231231-gen.pdf\u001b[0m\u001b[32;1m\u001b[1;3mI have found some information regarding Tesla's financial performance in 2023, but I still need to find specific financial goals for the year. Additionally, I need to find information about the next auto show Tesla will participate in.\n",
            "\n",
            "Action: WebSearch\n",
            "\n",
            "Action Input: Tesla financial goals 2023\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mTitle: Tesla Full Year 2023 Analysis — A Review of Actual ...\n",
            "Snippet: Tesla earned $13.2 billion in Operating Cash Flow and $4.3 billion in Free Cash Flow in 2023, spending $8.9 billion on Capital Expenditure. The ...\n",
            "Link: https://medium.com/@nambos3rd/tesla-full-year-2023-analysis-a-review-of-actual-performance-my-financial-forecast-579771d7d452\n",
            "\n",
            "Title: Tesla's 2023 Impact Report\n",
            "Snippet: In addition, we aim to transition our operational electricity load to 100% renewables well before we achieve our net-zero emissions goal and to continue.\n",
            "Link: https://www.tesla.com/ns_videos/2023-tesla-impact-report-highlights.pdf\n",
            "\n",
            "Title: tsla-20231231-gen.pdf\n",
            "Snippet: We also have audited the Company's internal control over financial reporting as of December 31, 2023, based on criteria established in.\n",
            "Link: https://ir.tesla.com/_flysystem/s3/sec/000162828024002390/tsla-20231231-gen.pdf\u001b[0m\u001b[32;1m\u001b[1;3mI have found some information regarding Tesla's financial performance in 2023, but I still need to find specific financial goals for the year. Additionally, I need to find information about the next auto show Tesla will participate in.\n",
            "\n",
            "Action: WebSearch\n",
            "\n",
            "Action Input: Tesla next auto show participation 2023\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mTitle: Tesla will participate in 2023 Munich auto show\n",
            "Snippet: Tesla joins German automakers taking part in the show, along with Chinese brands including BYD, FAW's Hongqi brand, Leapmotor, Seres and ...\n",
            "Link: https://www.autonews.com/munich-auto-show/tesla-will-participate-2023-munich-auto-show/\n",
            "\n",
            "Title: Everything that stood out to us at the 2023 New York Auto ...\n",
            "Snippet: The 2023 New York International Auto Show was all about EVs, software, and big trucks and SUVs. Find out what stood out to TechCrunch.\n",
            "Link: https://techcrunch.com/2023/04/06/everything-that-stood-out-to-us-at-the-2023-new-york-auto-show/\n",
            "\n",
            "Title: Tesla to Join 2023 Detroit Auto Show\n",
            "Snippet: Tesla will join the 2023 Detroit Auto Show that will take place September 13-24. The company will showcase its vehicles at the Powering ...\n",
            "Link: https://driveteslacanada.ca/news/tesla-to-join-2023-detroit-auto-show/\u001b[0m\u001b[32;1m\u001b[1;3mI have gathered the necessary information to answer the question.\n",
            "\n",
            "1. **Directors of Tesla and their LinkedIn handles:**\n",
            "   - Elon Musk (LinkedIn: [Elon Musk](https://www.linkedin.com/in/elon-musk-tesla-company-b7b00879))\n",
            "   - Robyn Denholm (LinkedIn: [Robyn Denholm](https://au.linkedin.com/in/robyn-denholm-a807795))\n",
            "   - Ira Ehrenpreis (LinkedIn: [Ira Ehrenpreis](https://www.linkedin.com/in/iraehrenpreis))\n",
            "   - Joseph Gebbia (LinkedIn: Profile not found)\n",
            "   - James Murdoch (LinkedIn: [James Murdoch](https://www.linkedin.com/in/jamesrmurdoch))\n",
            "   - Kimbal Musk (LinkedIn: [Kimbal Musk](https://www.linkedin.com/in/kimbal))\n",
            "   - JB Straubel (LinkedIn: [JB Straubel](https://www.linkedin.com/in/jb-straubel-b694981))\n",
            "   - Kathleen Wilson-Thompson (LinkedIn: [Kathleen Wilson-Thompson](https://www.linkedin.com/in/kathleen-wilson-thompson-275654201))\n",
            "\n",
            "2. **Tesla's financial goals for 2023:**\n",
            "   - Tesla aims to transition its operational electricity load to 100% renewables well before achieving its net-zero emissions goal. The company also focuses on maintaining strong financial performance, as evidenced by its $13.2 billion in Operating Cash Flow and $4.3 billion in Free Cash Flow in 2023.\n",
            "\n",
            "3. **Next auto show Tesla will participate in:**\n",
            "   - Tesla will participate in the 2023 Munich Auto Show.\n",
            "\n",
            "Final Answer:\n",
            "1. Directors of Tesla and their LinkedIn handles are provided above.\n",
            "2. Tesla's financial goals for 2023 include transitioning to 100% renewable electricity and maintaining strong financial performance.\n",
            "3. Tesla will participate in the 2023 Munich Auto Show.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "============================================================\n",
            "TOKEN USAGE AND COST REPORT\n",
            "============================================================\n",
            "Total Tokens Used: 7193\n",
            "Estimated Cost: $0.020881\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "config = defaultConfig.copy()\n",
        "\n",
        "processed_chunks, director_sections = load_and_process_filings(\n",
        "    config[\"companyFilingUrls\"],\n",
        "    config\n",
        ")\n",
        "\n",
        "vectorstore = create_vector_store(processed_chunks, config)\n",
        "\n",
        "retriever = create_retriever_with_reranking(vectorstore, config)\n",
        "\n",
        "tools = create_tools(config, director_sections, retriever)\n",
        "\n",
        "agent_executor = create_react_agent_executor(tools, config)\n",
        "\n",
        "question_for_cost_calculation = \"Who are the directors of Tesla. What are their linkedin handles? What are the financial goals of tesla this year. What is the next auto show that Tesla will participate in.\"\n",
        "\n",
        "total_tokens, estimated_cost = calculate_agent_tokens_and_cost(agent_executor, question_for_cost_calculation)\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"TOKEN USAGE AND COST REPORT\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(f\"Total Tokens Used: {total_tokens}\")\n",
        "print(f\"Estimated Cost: ${estimated_cost:.6f}\")\n",
        "print(f\"{'=' * 60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1094388",
      "metadata": {
        "id": "b1094388"
      },
      "source": [
        "**Reasoning — verification**\n",
        "\n",
        "After running the token/cost function:\n",
        "- Verify the printed totals match expectations.\n",
        "- Record the reported token breakdown if available (prompt vs completion).\n",
        "- Use these data to inform prompt engineering and tool usage to reduce cost.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee5ee5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bee5ee5a",
        "outputId": "6d508d99-5872-48dc-f6f5-18d3d538d7a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Tesla filing from https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm\n",
            "Processed 942 chunks from Tesla\n",
            "Loading General Motors filing from https://www.sec.gov/Archives/edgar/data/1467858/000146785824000031/gm-20231231.htm\n",
            "Processed 1085 chunks from General Motors\n",
            "Total processed chunks: 2027\n",
            "Creating vector store with OpenAI embeddings...\n",
            "Vector store created successfully\n",
            "Number of vectors: 2027\n",
            "Vector dimension: 1536\n",
            "Creating retriever with Flashrank reranking...\n",
            "Retriever with reranking created successfully\n",
            "Added tool: Company Directors Information\n",
            "Added tool: WebSearch\n",
            "Added tool: Vector Reranker Search\n",
            "Total tools created: 3\n",
            "Creating ReAct agent...\n",
            "ReAct agent created successfully\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo answer the question, I need to gather information on the directors of Tesla, their LinkedIn handles, Tesla's financial goals for this year, and the next auto show Tesla will participate in.\n",
            "\n",
            "First, I'll start by retrieving the names of the company directors for Tesla and their LinkedIn handles.\n",
            "\n",
            "Action: Company Directors Information\n",
            "\n",
            "Action Input: Tesla, true\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mDirectors of Tesla: Elon Musk (LinkedIn: https://www.linkedin.com/in/elon-musk-tesla-company-b7b00879); Robyn Denholm (LinkedIn: https://au.linkedin.com/in/robyn-denholm-a807795); Ira Ehrenpreis (LinkedIn: https://www.linkedin.com/in/iraehrenpreis); Joseph Gebbia (LinkedIn: Profile not found); James Murdoch (LinkedIn: https://www.linkedin.com/in/jamesrmurdoch); Kimbal Musk (LinkedIn: https://www.linkedin.com/in/kimbal); JB Straubel (LinkedIn: https://www.linkedin.com/in/jb-straubel-b694981); Kathleen Wilson-Thompson (LinkedIn: https://www.linkedin.com/in/kathleen-wilson-thompson-275654201)\u001b[0m\u001b[32;1m\u001b[1;3mI have obtained the names and LinkedIn handles of Tesla's directors. Next, I need to find information about Tesla's financial goals for this year.\n",
            "\n",
            "Action: Vector Reranker Search\n",
            "\n",
            "Action Input: What are Tesla's financial goals for this year?\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3mTesla\n",
            "consolidated balance sheets of Tesla, Inc. and its subsidiaries (the “Company”) as of December 31, 2023 and 2022, and the related consolidated statements of operations, of comprehensive income, of redeemable noncontrolling interests and equity and of cash flows for each of the three years in the period ended December 31, 2023, including the related notes (collectively referred to as the “consolidated financial statements”). We also have audited the Company's internal control over financial\n",
            "\n",
            "Tesla\n",
            "which oversees our ESG impacts, initiatives and priorities.Human Capital ResourcesA competitive edge for Tesla is its ability to attract and retain high quality employees. During the past year, Tesla made substantial investments in its workforce, further strengthening its standing as one of the most desirable and innovative companies to work for. As of December 31, 2023, our employee headcount worldwide was 140,473.We have created an environment that fosters growth opportunities, and as of this\n",
            "\n",
            "Tesla\n",
            "long-term liabilities— 3 Total liabilities$3,777 $2,215 Note 17 – Related Party TransactionsIn relation to our CEO’s exercise of stock options and sale of common stock from the 2012 CEO Performance Award, Tesla withheld the appropriate amount of taxes. However, given the significant amounts involved, our CEO entered into an indemnification agreement with us in November 2021 for additional taxes owed, if any. Tesla periodically does business with certain entities with which its CEO and directors\u001b[0m\u001b[32;1m\u001b[1;3mI have gathered some financial information about Tesla, but it doesn't specifically address their financial goals for this year. I need to perform a more targeted search to find Tesla's financial goals for 2023.\n",
            "\n",
            "Action: WebSearch\n",
            "\n",
            "Action Input: Tesla financial goals 2023\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mTitle: Tesla Full Year 2023 Analysis — A Review of Actual ...\n",
            "Snippet: Tesla earned $13.2 billion in Operating Cash Flow and $4.3 billion in Free Cash Flow in 2023, spending $8.9 billion on Capital Expenditure. The ...\n",
            "Link: https://medium.com/@nambos3rd/tesla-full-year-2023-analysis-a-review-of-actual-performance-my-financial-forecast-579771d7d452\n",
            "\n",
            "Title: Tesla's 2023 Impact Report\n",
            "Snippet: In addition, we aim to transition our operational electricity load to 100% renewables well before we achieve our net-zero emissions goal and to continue.\n",
            "Link: https://www.tesla.com/ns_videos/2023-tesla-impact-report-highlights.pdf\n",
            "\n",
            "Title: tsla-20231231-gen.pdf\n",
            "Snippet: We also have audited the Company's internal control over financial reporting as of December 31, 2023, based on criteria established in.\n",
            "Link: https://ir.tesla.com/_flysystem/s3/sec/000162828024002390/tsla-20231231-gen.pdf\u001b[0m\u001b[32;1m\u001b[1;3mI have found some information regarding Tesla's financial performance in 2023, but I still need to find specific financial goals for the year. I will now search for information about the next auto show Tesla will participate in.\n",
            "\n",
            "Action: WebSearch\n",
            "\n",
            "Action Input: Tesla next auto show participation 2023\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mTitle: Tesla will participate in 2023 Munich auto show\n",
            "Snippet: Tesla joins German automakers taking part in the show, along with Chinese brands including BYD, FAW's Hongqi brand, Leapmotor, Seres and ...\n",
            "Link: https://www.autonews.com/munich-auto-show/tesla-will-participate-2023-munich-auto-show/\n",
            "\n",
            "Title: Everything that stood out to us at the 2023 New York Auto ...\n",
            "Snippet: The 2023 New York International Auto Show was all about EVs, software, and big trucks and SUVs. Find out what stood out to TechCrunch.\n",
            "Link: https://techcrunch.com/2023/04/06/everything-that-stood-out-to-us-at-the-2023-new-york-auto-show/\n",
            "\n",
            "Title: Tesla to Join 2023 Detroit Auto Show\n",
            "Snippet: Tesla will join the 2023 Detroit Auto Show that will take place September 13-24. The company will showcase its vehicles at the Powering ...\n",
            "Link: https://driveteslacanada.ca/news/tesla-to-join-2023-detroit-auto-show/\u001b[0m\u001b[32;1m\u001b[1;3mI have gathered the necessary information to answer the question.\n",
            "\n",
            "1. **Directors of Tesla and their LinkedIn handles:**\n",
            "   - Elon Musk (LinkedIn: [Elon Musk](https://www.linkedin.com/in/elon-musk-tesla-company-b7b00879))\n",
            "   - Robyn Denholm (LinkedIn: [Robyn Denholm](https://au.linkedin.com/in/robyn-denholm-a807795))\n",
            "   - Ira Ehrenpreis (LinkedIn: [Ira Ehrenpreis](https://www.linkedin.com/in/iraehrenpreis))\n",
            "   - Joseph Gebbia (LinkedIn: Profile not found)\n",
            "   - James Murdoch (LinkedIn: [James Murdoch](https://www.linkedin.com/in/jamesrmurdoch))\n",
            "   - Kimbal Musk (LinkedIn: [Kimbal Musk](https://www.linkedin.com/in/kimbal))\n",
            "   - JB Straubel (LinkedIn: [JB Straubel](https://www.linkedin.com/in/jb-straubel-b694981))\n",
            "   - Kathleen Wilson-Thompson (LinkedIn: [Kathleen Wilson-Thompson](https://www.linkedin.com/in/kathleen-wilson-thompson-275654201))\n",
            "\n",
            "2. **Tesla's financial goals for 2023:**\n",
            "   - Tesla aims to transition its operational electricity load to 100% renewables well before achieving its net-zero emissions goal. The company also focuses on maintaining strong financial performance, as evidenced by its operating cash flow and capital expenditure figures.\n",
            "\n",
            "3. **Next auto show Tesla will participate in:**\n",
            "   - Tesla will participate in the 2023 Munich Auto Show.\n",
            "\n",
            "Final Answer:\n",
            "1. Directors of Tesla and their LinkedIn handles are provided above.\n",
            "2. Tesla's financial goals for 2023 include transitioning to 100% renewable electricity and maintaining strong financial performance.\n",
            "3. Tesla will participate in the 2023 Munich Auto Show.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "============================================================\n",
            "TOKEN USAGE AND COST REPORT\n",
            "============================================================\n",
            "Total Tokens Used: 5438\n",
            "Estimated Cost: $0.016059\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "config = defaultConfig.copy()\n",
        "\n",
        "processed_chunks, director_sections = load_and_process_filings(\n",
        "    config[\"companyFilingUrls\"],\n",
        "    config\n",
        ")\n",
        "\n",
        "vectorstore = create_vector_store(processed_chunks, config)\n",
        "\n",
        "retriever = create_retriever_with_reranking(vectorstore, config)\n",
        "\n",
        "tools = create_tools(config, director_sections, retriever)\n",
        "\n",
        "agent_executor = create_react_agent_executor(tools, config)\n",
        "\n",
        "question_for_cost_calculation = \"Who are the directors of Tesla. What are their linkedin handles? What are the financial goals of tesla this year. What is the next auto show that Tesla will participate in.\"\n",
        "\n",
        "total_tokens, estimated_cost = calculate_agent_tokens_and_cost(agent_executor, question_for_cost_calculation)\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"TOKEN USAGE AND COST REPORT\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(f\"Total Tokens Used: {total_tokens}\")\n",
        "print(f\"Estimated Cost: ${estimated_cost:.6f}\")\n",
        "print(f\"{'=' * 60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33867bba",
      "metadata": {
        "id": "33867bba"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide the final token usage and cost report for the agent's execution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b242505d",
      "metadata": {
        "id": "b242505d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "*   **Token usage and cost report for the agent's execution:**\n",
        "    *   Total Tokens Used: 5438\n",
        "    *   Estimated Cost: \\$0.016059\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `calculate_agent_tokens_and_cost` function successfully tracked token usage and cost for the agent's execution.\n",
        "*   The agent utilized 5438 tokens for the given query, resulting in an estimated cost of \\$0.016059.\n",
        "*   The agent's execution involved multiple tools including `Company Directors Information`, `Vector Reranker Search`, and `WebSearch` to answer the complex question.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Monitoring token usage and cost is crucial for optimizing LangChain agent deployments, especially for applications with high interaction volumes or complex queries.\n",
        "*   Future work could involve analyzing the token breakdown per tool or step within the agent's execution to identify potential areas for prompt engineering or tool optimization to reduce costs.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
