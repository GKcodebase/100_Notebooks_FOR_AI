{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0RTZ1dIyB1W"
   },
   "source": [
    "#  RAG with Reranker for 10-K filings\n",
    "\n",
    "## What is this Notebook About?\n",
    "\n",
    "This notebook demonstrates a **Retrieval-Augmented Generation (RAG)** system enhanced with a **Reranking** mechanism. Let's break down these concepts:\n",
    "\n",
    "### **What is RAG (Retrieval-Augmented Generation)?**\n",
    "RAG is a technique that combines two powerful AI approaches:\n",
    "1. **Retrieval**: Finding relevant documents/information from a knowledge base (like a database or document collection)\n",
    "2. **Generation**: Using an AI language model to generate answers based on the retrieved information\n",
    "\n",
    "Instead of relying solely on an LLM's training data, RAG retrieves specific, relevant documents first, then feeds them as context to the LLM to generate accurate, up-to-date answers. This approach is particularly useful for answering questions about specific documents like 10-K filings.\n",
    "\n",
    "### **What is Reranking?**\n",
    "In a basic RAG system, initial document retrieval uses embedding-based similarity search (fast but sometimes inaccurate). **Reranking** is a refinement step that uses a more sophisticated AI model (cross-encoder) to re-examine the retrieved documents and reorder them by true relevance to the query. This ensures the most relevant documents are prioritized for the LLM.\n",
    "\n",
    "### **What are 10-K Filings?**\n",
    "A 10-K is an annual report that public companies are required to file with the U.S. Securities and Exchange Commission (SEC). It contains comprehensive financial and operational information about the company.\n",
    "\n",
    "## Objective of This Exercise\n",
    "\n",
    "The objective of this notebook is to develop a prototype of a RAG system capable of answering questions based on Tesla's 10-K filings. Specifically, we will:\n",
    "1. Compare RAG responses **without** reranking vs **with** reranking\n",
    "2. Demonstrate how reranking improves answer quality\n",
    "3. Answer the following question: **\"List the major changes that occurred in the company in 2023?\"**\n",
    "\n",
    "**Note**: The spelling mistakes in the query (\"majour\" instead of \"major\", \"occoured\" instead of \"occurred\") are intentional. This tests the system's robustness to user input variations.\n",
    "\n",
    "**Data Source**: Tesla's 10-K filing from the SEC website (fiscal year 2023)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FACE-NEZaw16"
   },
   "source": [
    "# How to Run this Notebook?\n",
    "\n",
    "This notebook builds upon the notebook for Exercise 1: RAG with noReranker. The explanations that repeat from the previous notebook are greyed out in this notebook.\n",
    "\n",
    "1. Generate API key for OpenAI (ChatGPT): https://platform.openai.com/settings/organization/api-keys\n",
    "Make sure to save the API key. You'll get to see the key only once at the time of generation. If you miss copying the key, you may need to generate a new key.\n",
    "2. Click on ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADoAAAAkCAIAAABXBb6UAAADK0lEQVRYCe2Xz0vrQBDH/VezS2hUgjk09FJFEX+AB8VICMaTBS+FQgXRg4egYjw09CRY8SRBkcbQYggtsbsPXBj2JbE0zYvvPegcwnR2M/PpN7MTMkf/K5v7r2jpDLfI5zVTd6YuKDB9MwRBYNu2aZr6l5mmadt2EASQughnGtwgCA4PDzHGQsIwxoZh9Hq9IlgpzT7I2u22LMsJzt8Csiy32+0iiLOpe3d3J0kSoGGMK5XKwcGBruvValUURVgSRfH6+vqPE2fAdV13aWmJASGEDMPo9/s8UBiGJycn0CSLi4uPj4/8hvz+pLifn5+7u7uMVRTF09NTQkiyPCHEsiyQeX5+XsluZ2dnycwsMilup9OBNjg6OkplZRkJIbVajf2x6a71ej0vbr1eZ7UVRXl5eWHp3t/fd3Z20Jetrq52u10W931fVdXpWAVByItLCNnb22PlNU1j0g4Gg+3tbZ5pfX0d5u7FxYWexTRNg4GTFzcMw7W1NUYGuZ6enhYWFnhcjLHjOEzgrNfUEskkE/Vuaq77+/tSqcTjCoJg23ayxiSR1BLJGyfCHQ6HW1tbjOz4+JhlSTaoLMvPz89s9ePjw/vewjBk26Io8n3f8zzXdVdWVmIPcEpcSqlpmizX8vIyNOjNzQ0ILIri5eUlKzAYDDY2NmLC8z+ho/iBAxtgdXrc29tbhJAgCBhjy7Igked5V1dXlmW9vb1B0HEcGL0AwTsAVBRuv9+vVqusZLlcdl0X4GLO6+truVzm4ZJ+4biUUsuy4AWrKMrDw0MMlFLqum6lUmF8CKHz83No4NTuBHUlSWq1WmwzdHYy/0RHjd0WRZGu6yAVxnhzc9O27W6363me4zj7+/t8D+i6HkURlOTPfq1WY2StVou9LCVJ6nQ6sPk7JwMupTSKIsMwWBMDd9JBCGmaFhOJx03eUggupXQ0GjWbTRgIycKlUqnZbI5Go5hCfweXQQRB0Gg0VFUFpRFCqqo2Gg0Yc/8QLo8ShuFwOOQjqT4hpNfrwcmLOb7v842emmGaj5/vEv1MPNtR+xmmMVVmuGPEyb00Uze3hGMSzNQdI07upV9MOsjO+LCzRgAAAABJRU5ErkJggg==) icon in the left menu bar of this Notebook\n",
    "\n",
    "3. Click `+ Add new secret `\n",
    "- <font color=\"#d3d3d3\">Add OpenAI key, if not added already:\n",
    "  * <font color=\"#d3d3d3\">Under Name copy paste: `OPENAI_KEY`\n",
    "  * Under Value copy paste: OpenAI key you saved earlier\n",
    "\n",
    "4. Enable access to the keys for this notebook by toggling the radio buttons in the `Secrets` section.\n",
    "5. Close the `Secrets` section once done.\n",
    "6. Click `Run all` under the `Runtime` in top menu to execute this notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvPh7tDHyB1Z"
   },
   "source": [
    "#Basic Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2p5_tpSZrH81"
   },
   "source": [
    "\n",
    "## Install Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyuvJtpUrEVj"
   },
   "source": [
    "### **What are we installing?**\n",
    "\n",
    "Below is a brief explanation of each framework and library:\n",
    "\n",
    "**LangChain Ecosystem:**\n",
    "- `langchain`: A framework that simplifies building applications with Large Language Models (LLMs)\n",
    "- `langchain_core`: Core abstractions and interfaces for LangChain\n",
    "- `langchain_community`: Community integrations with external services and databases\n",
    "- `langchain_huggingface`: Integration with HuggingFace models for embeddings\n",
    "- `langchain_openai`: Integration with OpenAI's API for using GPT models\n",
    "\n",
    "**Vector Search & Embeddings:**\n",
    "- `faiss-cpu`: Facebook's open-source library for fast similarity search and clustering of vectors. It's optimized for CPU performance and is essential for storing and retrieving document embeddings efficiently\n",
    "- `openai==1.56.2`: OpenAI's official Python client library for accessing their APIs\n",
    "- `langchain_openai`: LangChain's wrapper around OpenAI's APIs\n",
    "\n",
    "**Reranking:**\n",
    "- `flashrank`: A fast, efficient reranking library that uses lightweight models to reorder retrieved documents by relevance\n",
    "- `langchain_cohere`: LangChain's integration with Cohere's API (an alternative reranking option)\n",
    "\n",
    "**Why these tools matter in our RAG pipeline:**\n",
    "- **LangChain**: Orchestrates the entire RAG workflow (retrieval → reranking → generation)\n",
    "- **FAISS**: Stores embeddings and performs fast semantic search\n",
    "- **HuggingFace Embeddings**: Converts text into numerical representations (embeddings) for similarity search\n",
    "- **OpenAI/GPT**: Generates the final answer based on context\n",
    "- **Flashrank**: Reranks retrieved documents to ensure the most relevant ones are used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tm2Y3oLZyB1Z"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain langchain_core langchain_community faiss-cpu openai langchain_openai langchain_huggingface -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_rq1aYHas8L"
   },
   "outputs": [],
   "source": [
    "# New installs\n",
    "%%capture\n",
    "!pip install -q U flashrank  # for Flashrank monkeypatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu0fuMI12r83",
    "outputId": "24d5c49a-cc51-49b7-b0a4-f9b93de0d693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.10\n"
     ]
    }
   ],
   "source": [
    "import importlib.metadata\n",
    "print(importlib.metadata.version(\"flashrank\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSeepaUCY2cA",
    "outputId": "7419020a-7b6d-4678-f7d9-ef612a790dc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain version: 1.0.5\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(f\"langchain version: {langchain.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjjMlvYfyB1a"
   },
   "source": [
    "## API Keys Setup\n",
    "\n",
    "### **Why do we need API keys?**\n",
    "An API key is a unique credential that authenticates your requests to external services. In this notebook, we need:\n",
    "\n",
    "- **OpenAI API Key**: Required to use GPT models for generating answers. You'll need to create an account at OpenAI and generate a key from their dashboard.\n",
    "- **HuggingFace API Key** (optional): Some embedding models may require authentication\n",
    "- **Cohere API Key** (optional): Alternative reranking service\n",
    "\n",
    "### **How to set up in Google Colab:**\n",
    "\n",
    "<font color=\"#d3d3d3\">\n",
    "**Important**: You need to setup your API keys in Google Colab's Secrets manager (a secure way to store credentials without exposing them in code). Click on the key icon in the left sidebar, then add your keys as:\n",
    "\n",
    "- `OPEN_AI_KEY` for OpenAI API Key\n",
    "\n",
    "**Security Note**: Never share your API keys! They grant access to your account and can incur costs. Always keep them confidential.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPHK9bhIVCy2"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqwr8z58yB1a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if 'google.colab' in str(get_ipython):\n",
    "    from google.colab import userdata\n",
    "    # Set environment variables\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPEN_AI_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zy9hcf9gJUuF"
   },
   "source": [
    "## Google Drive and Local Path Setup\n",
    "\n",
    "### **What are we doing here?**\n",
    "\n",
    "When running in Google Colab, we need to:\n",
    "1. **Mount Google Drive**: Connect your Google Drive to the Colab environment so we can read/write files\n",
    "2. **Create a FAISS Index Directory**: FAISS (Facebook AI Similarity Search) creates large vector store files that need to be stored. We create a directory to save the vector store locally.\n",
    "\n",
    "### **Why is this important?**\n",
    "- FAISS vector stores can be large (depending on the number of documents)\n",
    "- By saving to Google Drive, we can reuse the same vector store across multiple notebook runs\n",
    "- This avoids recreating embeddings every time, which is computationally expensive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqc39aerJTH1",
    "outputId": "1b33ab98-ebab-43f3-d2c0-2c2c708a99ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHCQ_v1ZJg3z"
   },
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "gdrive_root = Path('/content/drive/My Drive')\n",
    "faiss_dir = gdrive_root/\"LLM_Fall/RAG/faiss_index\"\n",
    "faiss_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5k6ahgnyB1a"
   },
   "source": [
    "## Import Libraries\n",
    "\n",
    "### **What are we importing?**\n",
    "\n",
    "Here we import all the necessary components for building our RAG pipeline. Let's understand each category:\n",
    "\n",
    "**Document Processing:**\n",
    "- `WebBaseLoader`: Loads and parses documents from web URLs\n",
    "- `RecursiveCharacterTextSplitter`: Breaks large documents into smaller, manageable chunks (essential for RAG, as embedding models have input length limits)\n",
    "\n",
    "**Embeddings & Vector Search:**\n",
    "- `HuggingFaceEmbeddings`: Converts text into numerical embeddings (vector representations) for semantic search\n",
    "- `FAISS`: Facebook's vector database that stores and retrieves embeddings efficiently\n",
    "\n",
    "**LLM & Prompt Management:**\n",
    "- `ChatOpenAI`: Interface to OpenAI's GPT models\n",
    "- `PromptTemplate`: Structures how we format input for the LLM\n",
    "- `StrOutputParser`: Parses and returns LLM output as text\n",
    "\n",
    "**RAG Pipeline Components:**\n",
    "- `RunnablePassthrough`: Passes data through unchanged (useful in LCEL chains)\n",
    "- `ContextualCompressionRetriever`: Orchestrates retrieval + reranking in a single retriever\n",
    "- `Document`: Represents a text document with metadata (e.g., source URL, page number)\n",
    "\n",
    "**Reranking:**\n",
    "- `FlashrankRerank`: Reranks retrieved documents using lightweight cross-encoder models\n",
    "- `Ranker`: The underlying reranking engine\n",
    "\n",
    "These components work together to create an efficient RAG pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feeydAIryB1a",
    "outputId": "90c77b90-3de4-495f-dd6f-116cda074931"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# LangChain imports\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from pprint import pprint\n",
    "\n",
    "from typing import List\n",
    "from langchain_classic.retrievers import ContextualCompressionRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rS3_BrbYcV8s"
   },
   "outputs": [],
   "source": [
    "# New imports\n",
    "from flashrank import Ranker, RerankRequest\n",
    "import langchain_community.document_compressors.flashrank_rerank as fr_mod\n",
    "fr_mod.RerankRequest = RerankRequest\n",
    "\n",
    "from langchain_community.document_compressors import FlashrankRerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Re7VZjvJbhCT"
   },
   "source": [
    "# Configuration Dictionary\n",
    "\n",
    "### **What is a Configuration Dictionary?**\n",
    "A configuration dictionary is a centralized place where we store all the settings and parameters for our RAG system. Instead of hardcoding values throughout the notebook, we define them once and reuse them. This makes the code more maintainable and allows us to easily experiment with different settings.\n",
    "\n",
    "### **What does each configuration parameter do?**\n",
    "\n",
    "**Document Processing Settings:**\n",
    "- `chunkSize`: Size of text chunks (in characters) when splitting documents. Smaller chunks = more specific, larger chunks = more context\n",
    "- `chunkOverlap`: Overlap between consecutive chunks (in characters). Overlap ensures context isn't lost at chunk boundaries\n",
    "- `userAgentHeader`: Identifies your application when fetching documents from the web (polite practice)\n",
    "\n",
    "**Embedding Model Settings:**\n",
    "- `embeddingModel`: The model used to convert text into numerical embeddings. \"BAAI/bge-base-en-v1.5\" is a HuggingFace model optimized for semantic search\n",
    "- Note: Embeddings are numerical representations that capture the semantic meaning of text, enabling similarity search\n",
    "\n",
    "**Vector Store & Retrieval Settings:**\n",
    "- `numRetrievedDocuments`: Number of documents initially retrieved by semantic search (12 documents). More documents = broader search, but slower\n",
    "- `numSelectedDocuments`: Number of documents passed to the LLM for answer generation (5 documents). Balances context quality with token costs\n",
    "\n",
    "**Reranking Settings:**\n",
    "- `rerankerType`: Type of reranker to use (\"flashrank\" = lightweight, fast cross-encoder)\n",
    "- `rerankerModel`: Specific reranking model (\"ms-marco-TinyBERT-L-2-v2\" is small but effective)\n",
    "- `numRerankedDocuments`: Number of documents returned after reranking (5 documents). These are the most relevant documents\n",
    "\n",
    "**LLM Settings:**\n",
    "- `ragAnswerModel`: The language model for generating answers (\"gpt-4o\" = OpenAI's GPT-4 Omni model)\n",
    "- `ragAnswerModelTemperature`: Controls randomness in responses (0.7 = balanced, 0.0 = deterministic, 1.0 = very random)\n",
    "\n",
    "**Data Source:**\n",
    "- `companyFilingUrls`: URL(s) to the 10-K filings we'll process\n",
    "\n",
    "**Prompt Template:**\n",
    "- `ragPromptTemplate`: The instruction template that tells the LLM how to format its response using the provided context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-Go6TKSbenl"
   },
   "outputs": [],
   "source": [
    "defaultConfig = {\n",
    "    # Document processing settings\n",
    "    \"chunkSize\": 500,\n",
    "    \"chunkOverlap\": 50,\n",
    "    \"userAgentHeader\": \"YourCompany-ResearchBot/1.0 (your@email.com)\",\n",
    "\n",
    "    # embedding model\n",
    "    \"embeddingModel\": \"BAAI/bge-base-en-v1.5\",\n",
    "\n",
    "    # Vector store settings\n",
    "    \"numRetrievedDocuments\": 12,\n",
    "\n",
    "    # Document formater settings\n",
    "    \"numSelectedDocuments\": 5,\n",
    "\n",
    "    # Reranker setting\n",
    "    \"rerankerType\": \"flashrank\",\n",
    "    \"rerankerModel\": \"ms-marco-TinyBERT-L-2-v2\",\n",
    "    \"numRerankedDocuments\": 5,\n",
    "\n",
    "    # Model settings\n",
    "    \"ragAnswerModel\": \"gpt-4o\",\n",
    "    \"ragAnswerModelTemeprature\": 0.7,\n",
    "\n",
    "    # URLs to process\n",
    "    \"companyFilingUrls\": [\n",
    "        (\"Tesla\", \"https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm\")\n",
    "    ],\n",
    "\n",
    "    # RAG prompt template\n",
    "    \"ragPromptTemplate\": \"\"\"\n",
    "    Give an answer for the `Question` using only the given `Context`. Use information relevant to the query from the entire context.\n",
    "    Provide a detailed answer with thorough explanations, avoiding summaries.\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7aBC2APb9pWc"
   },
   "outputs": [],
   "source": [
    "config = defaultConfig.copy() # Creates a separate copy of the default configuration dictionary (defaultConfig) so that any subsequent changes won't alter the original default settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySjUhhS-yB1b"
   },
   "source": [
    "# Load Vector Store\n",
    "\n",
    "### **What is a Vector Store?**\n",
    "\n",
    "A vector store is a database optimized for storing and searching numerical embeddings (vectors). Here's the concept:\n",
    "\n",
    "1. **Embeddings**: When documents are processed, each chunk is converted into a numerical vector (embedding) using an embedding model. These vectors capture semantic meaning—similar documents have similar vectors.\n",
    "\n",
    "2. **Vector Store**: A specialized database that stores these vectors and can quickly find the most similar vectors to a query using distance metrics (like cosine similarity).\n",
    "\n",
    "3. **FAISS Index**: FAISS (Facebook AI Similarity Search) creates highly optimized indexes for fast similarity search. It's one of the most efficient vector store implementations.\n",
    "\n",
    "### **Why are we loading a pre-existing vector store?**\n",
    "\n",
    "Creating embeddings is computationally expensive (requires processing and embedding all documents). By saving the vector store from our previous notebook, we can reuse it without regenerating embeddings. This is a common practice in production RAG systems.\n",
    "\n",
    "### **What happens in this section?**\n",
    "\n",
    "We will:\n",
    "1. Initialize an embedding function (the same model used to create the original embeddings)\n",
    "2. Load the FAISS index from disk\n",
    "3. This vector store is now ready for retrieval operations in our RAG pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geunm-dJyB1b"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model_name = config.get('embeddingModelName', 'text-embedding-3-small')\n",
    "\n",
    "if embedding_model_name.startswith(\"text-embedding\"):\n",
    "    # Use OpenAIEmbeddings for OpenAI models\n",
    "    embeddingFunction = OpenAIEmbeddings(model=embedding_model_name)\n",
    "else:\n",
    "    # Use HuggingFaceEmbeddings for other models (assuming they are from HuggingFace)\n",
    "    embeddingFunction = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "loaded_vectorstore = FAISS.load_local(str(faiss_dir), embeddingFunction, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IpelndxxEOz"
   },
   "source": [
    "# Retriever\n",
    "\n",
    "### **What is a Retriever?**\n",
    "\n",
    "A retriever is a component that fetches relevant documents from a knowledge base based on a query. In our case:\n",
    "\n",
    "1. **Input**: A user question (e.g., \"What technological advancements were made in Tesla's batteries?\")\n",
    "2. **Process**: The question is converted to an embedding, then compared against all document embeddings in the vector store using similarity search\n",
    "3. **Output**: The top-K most similar documents (in our config: 12 documents)\n",
    "\n",
    "### **How does semantic similarity work?**\n",
    "\n",
    "- Documents and queries are both converted to vectors using an embedding model\n",
    "- Similarity is calculated using cosine similarity: vectors pointing in similar directions = similar content\n",
    "- This is **fast** (milliseconds for large databases) but may not capture subtle nuances\n",
    "\n",
    "### **Why 12 documents?**\n",
    "\n",
    "- Retrieving more documents casts a wider net, increasing the chance of finding relevant information\n",
    "- But more documents means more noise and higher costs (more tokens for the LLM)\n",
    "- The trade-off: 12 is a good balance for most use cases\n",
    "- Later, reranking will filter these down to the 5 most relevant ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRde2x2gUs35"
   },
   "outputs": [],
   "source": [
    "retriever = loaded_vectorstore.as_retriever(search_kwargs={\"k\": config[\"numRetrievedDocuments\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AI3KriCiUtie"
   },
   "outputs": [],
   "source": [
    "retrieved_documents = retriever.invoke(\"What technological advancements were made in the batteries used in Tesla's Electric Vehicles?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMszDUCOU0aS",
    "outputId": "197bafe5-eb69-4e66-e888-123095523cef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='6479de32-a721-41b5-9ac8-5434aab44823', metadata={'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='technology featuring three electric motors for further increased performance in certain versions of Model S and Model X, Cybertruck and the Tesla Semi.We maintain extensive testing and R&D capabilities for battery cells, packs and systems, and have built an expansive body of knowledge on lithium-ion cell chemistry types and performance characteristics. In order to enable a greater supply of cells for our products with higher energy density at lower costs, we have developed a new proprietary'),\n",
       " Document(id='a9da26b9-1493-4255-91f4-2e38055e6acf', metadata={'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='electric vehicles to address additional vehicle markets, and to continue leveraging developments in our proprietary Full Self-Driving (“FSD”) Capability features, battery cell and other technologies.Energy Generation and StorageEnergy Storage ProductsPowerwall and Megapack are our lithium-ion battery energy storage products. Powerwall, which we sell directly to customers, as well as through channel partners, is designed to store energy at a home or small commercial facility. Megapack is an'),\n",
       " Document(id='da7034c4-de12-4438-8d17-a74f8b319846', metadata={'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='lower costs, we have developed a new proprietary lithium-ion battery cell and improved manufacturing processes.Vehicle Control and Infotainment SoftwareThe performance and safety systems of our vehicles and their battery packs utilize sophisticated control software. Control systems in our vehicles optimize performance, customize vehicle behavior, manage charging and control all infotainment functions. We develop almost all of this software, including most of the user interfaces, internally and'),\n",
       " Document(id='d4fee292-acdb-4a43-9de5-940272392c69', metadata={'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='PlansWe provide a manufacturer’s limited warranty on all new and used Tesla vehicles we sell directly to consumers, which may include limited warranties on certain components, specific types of damage or battery capacity retention. We also currently offer optional extended service plans that provide coverage beyond the new vehicle limited warranties for certain models in specified regions.7Table of ContentsEnergy Generation and StorageWe provide service and repairs to our energy product'),\n",
       " Document(id='25c57e24-477a-45c3-9a30-23d1022ae551', metadata={'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='Electric Co., Ltd.10-Q001-3475610.6October 29, 201910.36††2020 Pricing Agreement (Gigafactory 2170 Cells), entered into on June 9, 2020, by and among Registrant, Tesla Motors Netherlands B.V., Panasonic Corporation and Panasonic Corporation of North America.10-Q001-3475610.3July 28, 202010.37††2021 Pricing Agreement (Japan Cells) with respect to 2011 Supply Agreement, executed December 29, 2020, by and among the Registrant, Tesla Motors Netherlands B.V., Panasonic Corporation of North America'),\n",
       " Document(id='410d80ee-fa13-4b1c-87f2-577f2bb2bd45', metadata={'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content=\"other companies making electric vehicles and the world.Environmental, Social and Governance (ESG) and Human Capital ResourcesESGThe very purpose of Tesla's existence is to accelerate the world's transition to sustainable energy. We believe the world cannot reduce carbon emissions without addressing both energy generation and consumption, and we are designing and manufacturing a complete energy and transportation ecosystem to achieve this goal. As we expand, we are building each new factory to\"),\n",
       " Document(id='05b86e2a-be8d-4f26-80cf-a747e5621cac', metadata={'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='Tesla vehicle models, including controls over management’s significant assumptions related to the nature, frequency and costs of future claims as well as the completeness and accuracy of actual claims incurred to date. These procedures also included, among others, performing one of the following: (i) testing management’s process for determining the automotive warranty reserve for certain Tesla vehicle models or (ii) developing an independent estimate of the automotive warranty reserve for'),\n",
       " Document(id='8ca7ca2c-e506-4dd1-ae52-343a737004f9', metadata={'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='as of December 31, 2023. The Company provides a manufacturer’s warranty on all new and used Tesla vehicles. A warranty reserve is accrued for these products sold, which includes management’s best estimate of the projected costs to repair or replace items under warranty and recalls if identified. These estimates are based on actual claims incurred to date and an estimate of the nature, frequency and costs of future claims.The principal considerations for our determination that performing'),\n",
       " Document(id='3acd95a8-e3e2-4a8d-9785-208d2ac3fe8f', metadata={'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='The efficiency of our solar energy products is aided by our own solar inverter, which incorporates our power electronics technologies. We designed both products to integrate with Powerwall.Design and EngineeringAutomotiveWe have established significant in-house capabilities in the design and test engineering of electric vehicles and their components and systems. Our team has significant experience in computer-aided design as well as durability, strength and crash test simulations, which reduces'),\n",
       " Document(id='52a766d7-2f0c-438b-874f-95667691cfb0', metadata={'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='website, stores and galleries, as well as through our network of channel partners, and in the case of some commercial customers, through PPA transactions. We emphasize simplicity, standardization and accessibility to make it easy and cost-effective for customers to adopt clean energy, while reducing our customer acquisition costs. Service and WarrantyAutomotiveServiceWe provide service for our electric vehicles at our company-owned service locations and through Tesla Mobile Service technicians'),\n",
       " Document(id='2b623e81-1798-4121-8839-a41f7544452b', metadata={'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='or non-Tesla vehicle with the sale of a new or used Tesla vehicle. The Tesla and non-Tesla vehicles we acquire as trade-ins are subsequently remarketed, either directly by us or through third parties. We also remarket used Tesla vehicles acquired from other sources including lease returns.Public ChargingWe have a growing global network of Tesla Superchargers, which are our industrial-grade, high-speed vehicle chargers. Where possible, we co-locate Superchargers with our solar and energy storage'),\n",
       " Document(id='4d91cad6-f6cf-4ca1-ac61-e8d2739a5ef9', metadata={'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='vehicles and energy storage products. The use, storage and disposal of our battery packs are regulated under existing laws and are the subject of ongoing regulatory changes that may add additional requirements in the future. We have agreements with third party battery recycling companies to recycle our battery packs, and we are also piloting our own recycling technology.Solar Energy—GeneralWe are subject to certain state and federal regulations applicable to solar and battery storage providers')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wluh5VmxdqBU"
   },
   "source": [
    "#  Reranker: Improving Retrieval Quality\n",
    "\n",
    "## Why Reranking in RAG?\n",
    "\n",
    "### **The Problem with Initial Retrieval**\n",
    "\n",
    "Standard RAG systems use **bi-encoder embedding models** for initial retrieval:\n",
    "- **How they work**: The query and each document are encoded separately into vectors, then compared using cosine similarity\n",
    "- **Advantage**: Very fast, can handle millions of documents\n",
    "- **Disadvantage**: Limited - they miss nuanced relevance, context-dependent relationships, and subtle semantic connections\n",
    "\n",
    "### **The Reranking Solution**\n",
    "\n",
    "Rerankers use **cross-encoder models** that solve this problem:\n",
    "- **How they work**: The query and document are processed together as a pair, allowing the model to directly analyze their interaction and relationship\n",
    "- **What they capture**: Complex semantic relationships, contextual relevance, and precise relevance judgments that bi-encoders miss\n",
    "- **Trade-off**: Slower than bi-encoders, so we only use them on the top-K retrieved results (not all documents)\n",
    "\n",
    "### **Two-Stage Retrieval Architecture**\n",
    "\n",
    "Our RAG system uses a smart two-stage approach:\n",
    "\n",
    "```\n",
    "Stage 1: Fast Retrieval (Bi-encoder)\n",
    "├─ Query encoded separately → Search vector store\n",
    "└─ Return top 12 most similar documents\n",
    "\n",
    "Stage 2: Precise Reranking (Cross-encoder)\n",
    "├─ Take those 12 documents\n",
    "├─ Evaluate query-document pairs together\n",
    "└─ Return top 5 most relevant documents\n",
    "\n",
    "Final Stage: Generation\n",
    "├─ Pass top 5 documents as context to LLM\n",
    "└─ LLM generates answer\n",
    "```\n",
    "\n",
    "### **Real-World Impact**\n",
    "\n",
    "In large document collections (thousands to millions of chunks), retrieval errors are common. A document might rank high based on keyword similarity but actually be irrelevant to the semantic query. Reranking corrects these errors, ensuring high-quality context for the LLM.\n",
    "\n",
    "**Flashrank** is a lightweight, efficient reranking library that uses TinyBERT models—small but powerful cross-encoders optimized for speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnb1ikvhdy2R",
    "outputId": "a4a0a554-744e-49e0-8979-00b30661f781"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ms-marco-TinyBERT-L-2-v2.zip: 100%|██████████| 3.26M/3.26M [00:00<00:00, 138MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# Config (adjust as needed)\n",
    "model_name = config.get(\"rerankerModel\", \"ms-marco-TinyBERT-L-2-v2\")\n",
    "top_n = int(config.get(\"numRerankedDocuments\", 5))\n",
    "\n",
    "# Create client + LC wrapper\n",
    "ranker_client = Ranker(model_name=model_name)\n",
    "reranker = FlashrankRerank(client=ranker_client, model=model_name, top_n=top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWDOUvUS_h1z"
   },
   "outputs": [],
   "source": [
    "query = \"List the majour changes that occoured in the company in 2023\"\n",
    "reranked_docs = reranker.compress_documents(retrieved_documents, query)  # Returns 5 docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UR7BQxjfVjdh",
    "outputId": "e6a74c46-7d74-407c-dfd1-873c8accfae8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': 7, 'relevance_score': np.float32(0.06566119), 'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='as of December 31, 2023. The Company provides a manufacturer’s warranty on all new and used Tesla vehicles. A warranty reserve is accrued for these products sold, which includes management’s best estimate of the projected costs to repair or replace items under warranty and recalls if identified. These estimates are based on actual claims incurred to date and an estimate of the nature, frequency and costs of future claims.The principal considerations for our determination that performing'),\n",
       " Document(metadata={'id': 4, 'relevance_score': np.float32(7.1485716e-05), 'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='Electric Co., Ltd.10-Q001-3475610.6October 29, 201910.36††2020 Pricing Agreement (Gigafactory 2170 Cells), entered into on June 9, 2020, by and among Registrant, Tesla Motors Netherlands B.V., Panasonic Corporation and Panasonic Corporation of North America.10-Q001-3475610.3July 28, 202010.37††2021 Pricing Agreement (Japan Cells) with respect to 2011 Supply Agreement, executed December 29, 2020, by and among the Registrant, Tesla Motors Netherlands B.V., Panasonic Corporation of North America'),\n",
       " Document(metadata={'id': 11, 'relevance_score': np.float32(3.7210935e-05), 'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='vehicles and energy storage products. The use, storage and disposal of our battery packs are regulated under existing laws and are the subject of ongoing regulatory changes that may add additional requirements in the future. We have agreements with third party battery recycling companies to recycle our battery packs, and we are also piloting our own recycling technology.Solar Energy—GeneralWe are subject to certain state and federal regulations applicable to solar and battery storage providers'),\n",
       " Document(metadata={'id': 3, 'relevance_score': np.float32(2.7031123e-05), 'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='PlansWe provide a manufacturer’s limited warranty on all new and used Tesla vehicles we sell directly to consumers, which may include limited warranties on certain components, specific types of damage or battery capacity retention. We also currently offer optional extended service plans that provide coverage beyond the new vehicle limited warranties for certain models in specified regions.7Table of ContentsEnergy Generation and StorageWe provide service and repairs to our energy product'),\n",
       " Document(metadata={'id': 5, 'relevance_score': np.float32(2.6763053e-05), 'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content=\"other companies making electric vehicles and the world.Environmental, Social and Governance (ESG) and Human Capital ResourcesESGThe very purpose of Tesla's existence is to accelerate the world's transition to sustainable energy. We believe the world cannot reduce carbon emissions without addressing both energy generation and consumption, and we are designing and manufacturing a complete energy and transportation ecosystem to achieve this goal. As we expand, we are building each new factory to\")]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reranked_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v02CFzjoZnYk"
   },
   "source": [
    "## ContextualCompressionRetriever\n",
    "\n",
    "### **What is ContextualCompressionRetriever?**\n",
    "\n",
    "ContextualCompressionRetriever is a LangChain component that combines two operations into a single, unified retriever:\n",
    "\n",
    "1. **Base Retrieval**: Fetches initial documents from the vector store (bi-encoder based, fast)\n",
    "2. **Compression/Reranking**: Reranks those documents using a cross-encoder (more accurate but slower)\n",
    "\n",
    "Think of it as a pipeline: retrieve many → filter to best → return.\n",
    "\n",
    "### **Architecture**\n",
    "\n",
    "```\n",
    "ContextualCompressionRetriever\n",
    "├─ base_retriever: FAISS vector store retriever\n",
    "│   └─ Returns top 12 documents based on embedding similarity\n",
    "└─ base_compressor: Flashrank reranker\n",
    "    └─ Reranks those 12 documents and returns top 5\n",
    "```\n",
    "\n",
    "### **Why Use ContextualCompressionRetriever?**\n",
    "\n",
    "**Without ContextualCompressionRetriever**, you'd need to:\n",
    "```python\n",
    "docs = retriever.invoke(query)           # Get 12 docs\n",
    "reranked = reranker.compress_documents(docs, query)  # Rerank manually\n",
    "```\n",
    "\n",
    "**With ContextualCompressionRetriever**, you can:\n",
    "```python\n",
    "docs = retriever.invoke(query)  # Done! Automatically handles both steps\n",
    "```\n",
    "\n",
    "### **Key Advantages**\n",
    "\n",
    "1. **Single Interface**: Acts like a regular retriever, but with reranking built-in\n",
    "2. **Cleaner Code**: Abstracts away the complexity of manually orchestrating retrieval + reranking\n",
    "3. **Production-Ready**: \n",
    "   - Proper error handling (e.g., if reranker fails, falls back to base retrieval)\n",
    "   - Callback support for monitoring and debugging\n",
    "   - Handles edge cases (empty results, malformed documents, etc.)\n",
    "4. **Scalability**: Can be easily swapped in/out in any RAG pipeline\n",
    "5. **Async Support**: Built-in support for asynchronous operations for high-throughput scenarios\n",
    "\n",
    "### **How it improves RAG**\n",
    "\n",
    "By ensuring only the most relevant documents are passed to the LLM, ContextualCompressionRetriever:\n",
    "- Reduces token usage (smaller context = lower costs)\n",
    "- Improves answer quality (less noise and irrelevant information)\n",
    "- Speeds up generation (LLM has less to process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwfabpBaWycQ"
   },
   "outputs": [],
   "source": [
    "from langchain_classic.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "retriever = ContextualCompressionRetriever(\n",
    "        base_compressor = reranker, base_retriever = retriever\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bd-xd3qJcYS9",
    "outputId": "4760386c-c53d-4573-8778-008b2272f156"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': 2, 'relevance_score': np.float32(0.63399494), 'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='of its operations and its cash flows for each of the three years in the period ended December 31, 2023 in conformity with accounting principles generally accepted in the United States of America. Also in our opinion, the Company maintained, in all material respects, effective internal control over financial reporting as of December 31, 2023, based on criteria established in Internal Control - Integrated Framework (2013) issued by the COSO.Changes in Accounting PrinciplesAs discussed in Note 2'),\n",
       " Document(metadata={'id': 10, 'relevance_score': np.float32(0.5138425), 'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='the degree of compliance with the policies or procedures may deteriorate.Changes in Internal Control over Financial ReportingThere was no change in our internal control over financial reporting that occurred during the quarter ended December 31, 2023, which has materially affected, or is reasonably likely to materially affect, our internal control over financial reporting.93ITEM 9B. OTHER INFORMATIONNone of the Company’s directors or officers adopted, modified or terminated a Rule 10b5-1'),\n",
       " Document(metadata={'id': 4, 'relevance_score': np.float32(0.21164596), 'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content=\"consolidated balance sheets of Tesla, Inc. and its subsidiaries (the “Company”) as of December 31, 2023 and 2022, and the related consolidated statements of operations, of comprehensive income, of redeemable noncontrolling interests and equity and of cash flows for each of the three years in the period ended December 31, 2023, including the related notes (collectively referred to as the “consolidated financial statements”). We also have audited the Company's internal control over financial\"),\n",
       " Document(metadata={'id': 3, 'relevance_score': np.float32(0.16434783), 'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='Annual Report on Form 10-K for fiscal year 2022, which was filed with the Securities and Exchange Commission on January 31, 2023.Overview and 2023 HighlightsOur mission is to accelerate the world’s transition to sustainable energy. We design, develop, manufacture, lease and sell high-performance fully electric vehicles, solar energy generation systems and energy storage products. We also offer maintenance, installation, operation, charging, insurance, financial and other services related to our'),\n",
       " Document(metadata={'id': 6, 'relevance_score': np.float32(0.037538964), 'source': 'https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm', 'title': 'tsla-20231231', 'language': 'No language found.', 'company': 'Tesla'}, page_content='these changes would have had on our net income before income taxes. These changes would have resulted in a gain or loss of $1.01\\xa0billion at December\\xa031, 2023 and $473\\xa0million at December\\xa031, 2022, assuming no foreign currency hedging.45ITEM 8. FINANCIAL STATEMENTS AND SUPPLEMENTARY DATAIndex to Consolidated Financial StatementsPageReport of Independent Registered Public Accounting Firm (PCAOB ID: 238)47Consolidated Balance Sheets49Consolidated Statements of Operations50Consolidated Statements')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCAROLd2-vU2"
   },
   "outputs": [],
   "source": [
    "def create_retriever_with_reranking(vectorstore, config, use_reranking = True ):\n",
    "    \"\"\"\n",
    "    Creates a retriever with optional reranking capability.\n",
    "\n",
    "    Args:\n",
    "        vectorstore: The vector store to retrieve from\n",
    "        config: Configuration dictionary\n",
    "        use_reranking: Whether to use reranking (default: True)\n",
    "\n",
    "    Returns:\n",
    "        A retriever (either basic or with reranking)\n",
    "    \"\"\"\n",
    "    # Create base retriever\n",
    "    base_retriever = vectorstore.as_retriever(\n",
    "        search_kwargs={\"k\": config.get(\"numRetrievedDocuments\", 12)}\n",
    "    )\n",
    "\n",
    "    # If reranking is disabled, return the base retriever\n",
    "    if not use_reranking:\n",
    "        return base_retriever\n",
    "\n",
    "    try:\n",
    "        # Initialize the reranker\n",
    "        model_name = config.get(\"rerankerModel\", \"ms-marco-TinyBERT-L-2-v2\")\n",
    "        top_n = int(config.get(\"numRerankedDocuments\", 5))\n",
    "        ranker_client = Ranker(model_name=model_name)\n",
    "        reranker = FlashrankRerank(client=ranker_client, model=model_name, top_n=top_n)\n",
    "\n",
    "\n",
    "        # Create and return the enhanced retrieval system\n",
    "        return ContextualCompressionRetriever(base_retriever=base_retriever, base_compressor=reranker)\n",
    "    except Exception as e:\n",
    "        print(f\" Error setting up reranker: {e}\")\n",
    "        print(\"Falling back to base retriever.\")\n",
    "        return base_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xOFgE0nyB1c"
   },
   "source": [
    "# RAG Chain: Putting It All Together\n",
    "\n",
    "## What is a RAG Chain?\n",
    "\n",
    "A RAG chain is a pipeline that connects all components of a Retrieval-Augmented Generation system into a cohesive workflow. Each component processes the input and passes its output to the next component.\n",
    "\n",
    "### **RAG Chain Components & Flow**\n",
    "\n",
    "```\n",
    "User Query\n",
    "    ↓\n",
    "[RETRIEVER] - Fetch relevant documents from vector store\n",
    "    ├─ Semantic similarity search (bi-encoder)\n",
    "    └─ Rerank results (cross-encoder) \n",
    "    ↓\n",
    "[DOCUMENT FORMATTER] - Convert documents into readable context\n",
    "    ├─ Select top-5 documents\n",
    "    └─ Format as: \"Company Name\\nDocument Content\"\n",
    "    ↓\n",
    "[PROMPT TEMPLATE] - Structure the input for the LLM\n",
    "    ├─ Question: {user query}\n",
    "    └─ Context: {formatted documents}\n",
    "    ↓\n",
    "[LLM] - Generate answer based on context\n",
    "    ├─ Model: GPT-4o\n",
    "    └─ Temperature: 0.7 (balanced creativity)\n",
    "    ↓\n",
    "[OUTPUT PARSER] - Extract and format the response\n",
    "    ↓\n",
    "Final Answer\n",
    "```\n",
    "\n",
    "### **Component Descriptions**\n",
    "\n",
    "1. **Retriever**: Searches the vector store and optionally reranks documents\n",
    "   - Without reranking: Fast but potentially less accurate\n",
    "   - With reranking: Slower but ensures relevant documents are selected\n",
    "\n",
    "2. **Document Formatter**: Transforms raw documents into readable text\n",
    "   - Extracts document content and metadata (company name)\n",
    "   - Limits to top-5 documents to control context size\n",
    "   - Joins documents with clear separators for the LLM\n",
    "\n",
    "3. **LLM (Large Language Model)**: The \"brain\" that generates answers\n",
    "   - Takes the formatted context and question\n",
    "   - Uses its training to synthesize an answer based only on provided context\n",
    "   - GPT-4o is chosen for its reasoning capabilities and cost-effectiveness\n",
    "\n",
    "4. **Prompt Template**: Instructions that guide the LLM\n",
    "   - Tells the LLM to only use provided context (not general knowledge)\n",
    "   - Requests detailed answers with thorough explanations\n",
    "   - Structures the input in a clear format\n",
    "\n",
    "5. **Output Parser**: Extracts the text response from the LLM\n",
    "   - The LLM returns structured objects; the parser extracts just the text\n",
    "\n",
    "### **LCEL (LangChain Expression Language)**\n",
    "\n",
    "The code uses LCEL, LangChain's composable syntax:\n",
    "```python\n",
    "retriever | format_docs  # Pass retriever output to formatter\n",
    "| prompt               # Pass to prompt template\n",
    "| llm                 # Pass to LLM\n",
    "| parser              # Parse the output\n",
    "```\n",
    "\n",
    "This pipe syntax (`|`) chains components together, making the pipeline easy to read and modify.\n",
    "\n",
    "### **Why Separate Retrieval from Formatting?**\n",
    "\n",
    "The LCEL chain separates concerns:\n",
    "- Retriever handles document search\n",
    "- Formatter handles document presentation\n",
    "- Prompt handles instruction\n",
    "- LLM handles generation\n",
    "\n",
    "This modular design makes it easy to swap components (e.g., use a different reranker or LLM) without changing the entire pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3qPMDemyMEz"
   },
   "outputs": [],
   "source": [
    "def create_rag_chain(vectorstore, config, use_reranking=True):\n",
    "    \"\"\"\n",
    "    Creates a RAG chain with optional reranking.\n",
    "\n",
    "    Args:\n",
    "        vectorstore: The vector store\n",
    "        config: Configuration dictionary\n",
    "        use_reranking: Whether to use reranking\n",
    "\n",
    "    Returns:\n",
    "        A runnable RAG chain\n",
    "    \"\"\"\n",
    "    # Create retriever with optional reranking\n",
    "    retriever = create_retriever_with_reranking(\n",
    "        vectorstore=vectorstore,\n",
    "        config=config,\n",
    "        use_reranking=use_reranking\n",
    "    )\n",
    "\n",
    "    # Define formatting function\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join([\n",
    "            f\"{doc.metadata.get('company', '')}\\n{doc.page_content}\"\n",
    "            for doc in docs[:config.get(\"numSelectedDocuments\", 5)]\n",
    "        ])\n",
    "\n",
    "    # Create LLM\n",
    "    llm = ChatOpenAI(\n",
    "        model=config[\"ragAnswerModel\"],\n",
    "        temperature=config.get(\"ragAnswerModelTemperature\", 0.7)\n",
    "    )\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = PromptTemplate.from_template(config[\"ragPromptTemplate\"])\n",
    "\n",
    "    # Build and return RAG chain\n",
    "    return (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WV1CoiO_ZxQ"
   },
   "outputs": [],
   "source": [
    "rag_chain_with_reranking = create_rag_chain(loaded_vectorstore, config, use_reranking=True)\n",
    "rag_chain_without_reranking = create_rag_chain(loaded_vectorstore, config, use_reranking=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-aQBERyl_aRu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RGO_8l3354c"
   },
   "source": [
    "# Question\n",
    "\n",
    "Note: The spelling mistakes in the query are intentional. We use only one 10-K document to ensure that the code runs within a reasonable time in the free Colab version, thereby reducing preprocessing time. The retrieval performs well even without the Reranker for many queries due to the smaller number of chunks. Therefore, to demonstrate the value of the Reranker, we identified a query that consistently underperforms without reranker.\n",
    "\n",
    "In real-world scenarios, datasets are much larger and cosine based similarity often make mistakes in ranking chunks. Hence, a base retriever alone is typically insufficient without a Reranker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQR7YDyD4FRP"
   },
   "outputs": [],
   "source": [
    "question = \"List the majour changes that occoured in the company in 2023\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIUSGAihyB1c"
   },
   "source": [
    "# Answer without ReRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zo2UoQhLyB1c",
    "outputId": "b3e5616d-828b-46a1-e686-4b5ef8a7653e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('In 2023, Tesla underwent several major changes, particularly in its '\n",
      " 'financial structure and operational strategies. Here are the detailed '\n",
      " 'changes:\\n'\n",
      " '\\n'\n",
      " '1. **Restructuring and Other Financial Adjustments**: In the context '\n",
      " 'provided for the year 2023, there is a noted absence of restructuring costs, '\n",
      " 'contrasting with the significant restructuring costs of $176 million '\n",
      " 'recorded in 2022. This indicates a potential stabilization or completion of '\n",
      " 'major restructuring efforts that were previously necessary.\\n'\n",
      " '\\n'\n",
      " '2. **Selling, General, and Administrative (SG&A) Expenses**: Tesla '\n",
      " 'experienced a notable increase in its SG&A expenses in 2023, with these '\n",
      " 'costs rising to $4,800 million from $3,946 million in 2022, reflecting a '\n",
      " '$854 million increase, which constitutes a 22% rise. This increase could be '\n",
      " 'attributed to expanded operations, increased personnel costs, or investment '\n",
      " 'in marketing and sales efforts. As a percentage of revenue, SG&A expenses '\n",
      " 'remained at 5%, suggesting that while absolute expenses increased, they '\n",
      " 'scaled proportionately with revenue growth.\\n'\n",
      " '\\n'\n",
      " '3. **Internal Controls and Financial Reporting**: Tesla maintained effective '\n",
      " 'internal control over financial reporting as of December 31, 2023. This is '\n",
      " 'based on the criteria established in the Internal Control - Integrated '\n",
      " 'Framework (2013) issued by the Committee of Sponsoring Organizations of the '\n",
      " \"Treadway Commission (COSO). This demonstrates Tesla's commitment to robust \"\n",
      " 'financial governance and compliance with accounting standards.\\n'\n",
      " '\\n'\n",
      " '4. **Sustainable Energy Mission**: The company continued to focus on its '\n",
      " \"mission to accelerate the world's transition to sustainable energy. This \"\n",
      " 'ongoing commitment is reflected through its activities in designing, '\n",
      " 'developing, manufacturing, leasing, and selling electric vehicles, solar '\n",
      " 'energy generation systems, and energy storage products. Additionally, '\n",
      " \"Tesla's expansion in offering services related to maintenance, installation, \"\n",
      " 'operation, charging, insurance, and financial services supports its broader '\n",
      " 'strategic objectives.\\n'\n",
      " '\\n'\n",
      " \"These changes collectively highlight Tesla's strategic focus on growth, \"\n",
      " 'sustainability, and robust financial management throughout 2023.')\n"
     ]
    }
   ],
   "source": [
    "answer_without_reranking = rag_chain_without_reranking.invoke(question)\n",
    "pprint(answer_without_reranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LV6ldo9TyB1c"
   },
   "source": [
    "# Answer with ReRanking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pgi2eBssyB1c",
    "outputId": "2d8616e7-fa26-436d-9fb0-811f06e93117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('In 2023, Tesla experienced several notable changes and developments:\\n'\n",
      " '\\n'\n",
      " '1. **Financial Reporting and Internal Controls:**\\n'\n",
      " '   - Tesla continued to maintain effective internal control over financial '\n",
      " 'reporting as of December 31, 2023, in accordance with the criteria '\n",
      " 'established in the Internal Control - Integrated Framework (2013) issued by '\n",
      " 'COSO. Despite concerns that the degree of compliance with policies or '\n",
      " 'procedures may deteriorate, no material changes in internal control over '\n",
      " 'financial reporting were noted during the last quarter of 2023.\\n'\n",
      " '\\n'\n",
      " '2. **Changes in Accounting Principles:**\\n'\n",
      " \"   - The company's financial statements for the period ending December 31, \"\n",
      " '2023, were prepared in conformity with generally accepted accounting '\n",
      " 'principles in the United States. Specific changes in accounting principles '\n",
      " 'were discussed in Note 2, though the exact nature of these changes is not '\n",
      " 'detailed in the provided context.\\n'\n",
      " '\\n'\n",
      " '3. **Financial Performance and Gains:**\\n'\n",
      " \"   - Tesla's financial performance saw significant fluctuations, with \"\n",
      " 'changes having a hypothetical impact of a $1.01 billion gain or loss at the '\n",
      " 'end of 2023, compared to $473 million at the end of 2022. This was analyzed '\n",
      " 'under the assumption of no foreign currency hedging.\\n'\n",
      " '\\n'\n",
      " '4. **Business Operations and Offerings:**\\n'\n",
      " '   - Tesla continued its mission to accelerate the transition to sustainable '\n",
      " 'energy by designing, developing, manufacturing, leasing, and selling '\n",
      " 'high-performance fully electric vehicles, solar energy generation systems, '\n",
      " 'and energy storage products. The company also expanded its service offerings '\n",
      " 'to include maintenance, installation, operation, charging, insurance, '\n",
      " 'financial services, and other related services.\\n'\n",
      " '\\n'\n",
      " '5. **Annual Reporting:**\\n'\n",
      " \"   - The company's Annual Report on Form 10-K for the fiscal year 2022 was \"\n",
      " 'filed with the Securities and Exchange Commission on January 31, 2023, '\n",
      " 'indicating a continuous commitment to transparency and regulatory '\n",
      " 'compliance.\\n'\n",
      " '\\n'\n",
      " \"Overall, while the context provides insights into Tesla's financial and \"\n",
      " 'operational areas, it does not specify any drastic or new strategic changes '\n",
      " 'in 2023 beyond maintaining and expanding its existing operations and '\n",
      " 'ensuring robust internal controls and financial reporting.')\n"
     ]
    }
   ],
   "source": [
    "answer_with_reranking = rag_chain_with_reranking.invoke(question)\n",
    "pprint(answer_with_reranking)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
